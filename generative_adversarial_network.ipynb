{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKQppapXvRM5qPw7RFDfLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haruka-inb/pytorch_practice/blob/main/generative_adversarial_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network"
      ],
      "metadata": {
        "id": "RIkITMwXNUZa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0OSUkzqHtxb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "latent_size = 64\n",
        "hidden_size = 256\n",
        "image_size = 784\n",
        "# num_epochs = 200\n",
        "num_epochs = 20\n",
        "batch_size = 100\n",
        "sample_dir = 'samples'\n",
        "\n",
        "# Create a directory to store the generated images if not exits\n",
        "if not os.path.exists(sample_dir):\n",
        "  os.mkdir(sample_dir)\n",
        "\n",
        "# Process image: normalize with mean=0.5, std=0.5\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=0.5, std=0.5)])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='/../../data', train=True,\n",
        "                                      transform=transform, download=True)\n",
        "\n",
        "# Create a data loader\n",
        "data_loader = torch.utils.data.DataLoader(mnist, batch_size=batch_size,\n",
        "                                           shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "s3x6JYZ9YpoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(image_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Generator\n",
        "G = nn.Sequential(\n",
        "    nn.Linear(latent_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, image_size),\n",
        "    nn.Tanh()\n",
        ")\n",
        "\n",
        "# transfer models to GPUs\n",
        "D = D.to(device)\n",
        "G = G.to(device)\n",
        "\n",
        "# Define binary cross entropy loss and Adam optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.002)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.002)\n",
        "\n",
        "# Define the method denorm()\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "# Define the method reset_grad()\n",
        "def reset_grad():\n",
        "  d_optimizer.zero_grad()\n",
        "  g_optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "77dDpVPPYs6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "for e in range(num_epochs):\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "    images = images.reshape(batch_size, -1).to(device)\n",
        "\n",
        "    # Create the labels which are later used as input for the BCE loss\n",
        "    # label real images as 1 and fake images as 0\n",
        "    real_labels = torch.ones(batch_size, 1).to(device)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "    # ================================================================== #\n",
        "    #                      Train the discriminator                       #\n",
        "    # ================================================================== #\n",
        "    # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "    # Second term of the loss is always zero since real_labels == 1\n",
        "    outputs = D(images)\n",
        "    d_loss_real = criterion(outputs, real_labels)\n",
        "    real_score = outputs\n",
        "\n",
        "    # Compute BCELoss using fake images\n",
        "    # First term of the loss is always zero since fake_labels == 0\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    fake_images = G(z)\n",
        "    outputs = D(fake_images)\n",
        "    d_loss_fake =  criterion(outputs, fake_labels)\n",
        "    fake_score = outputs\n",
        "\n",
        "    # Backprop and optimize\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    reset_grad()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    # ================================================================== #\n",
        "    #                        Train the generator                         #\n",
        "    # ================================================================== #\n",
        "    # Compute loss with fake images\n",
        "    z = torch.randn(batch_size, latent_size).to(device)\n",
        "    fake_images = G(z)\n",
        "    outputs = D(fake_images)\n",
        "\n",
        "    # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "    g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "    # Backprop and optimize\n",
        "    reset_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    if (i+1) % 200 == 0:\n",
        "      print(f\"Epoch {e}/{num_epochs}, Steps {i}/{len(data_loader)}, d_loss: {d_loss.item()}, g_loss: {g_loss.item()}, D(x): {real_score.mean().item()}, G(x): {fake_score.mean().item()}\")\n",
        "\n",
        "  # Save real images\n",
        "  if (e+1) == 1:\n",
        "    images = images.reshape(images.size(0), 1, 28, 28)\n",
        "    save_image(denorm(images), os.path.join(sample_dir, 'realimages.png'))\n",
        "\n",
        "  # Save sampled images\n",
        "  fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
        "  save_image(denorm(images), os.path.join(sample_dir, 'fake_images-{}.png'.format(e+1)))\n",
        "\n",
        "# Save the model checkpoints\n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ],
      "metadata": {
        "id": "UHwuGIvONgCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8088b2ab-a354-41df-d105-2caf6eac3f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/20, Steps 199/600, d_loss: 0.016027158126235008, g_loss: 6.685244083404541, D(x): 0.9961581230163574, G(x): 0.012034215964376926\n",
            "Epoch 0/20, Steps 399/600, d_loss: 1.0172320799028967e-05, g_loss: 98.96879577636719, D(x): 0.9999897480010986, G(x): 7.286766027473692e-40\n",
            "Epoch 0/20, Steps 599/600, d_loss: 1.2976300240552519e-05, g_loss: 99.07817840576172, D(x): 0.999987006187439, G(x): 1.2509890253280942e-37\n",
            "Epoch 1/20, Steps 199/600, d_loss: 4.2743417907331605e-06, g_loss: 97.8670425415039, D(x): 0.9999957084655762, G(x): 1.382111044972203e-38\n",
            "Epoch 1/20, Steps 399/600, d_loss: 2.6667642032407457e-06, g_loss: 98.30533599853516, D(x): 0.9999973177909851, G(x): 4.130481366428474e-39\n",
            "Epoch 1/20, Steps 599/600, d_loss: 1.9930444977944717e-05, g_loss: 98.89678192138672, D(x): 0.9999801516532898, G(x): 9.027356685070084e-39\n",
            "Epoch 2/20, Steps 199/600, d_loss: 7.808275199749914e-07, g_loss: 98.41651916503906, D(x): 0.9999992251396179, G(x): 2.9346398816444973e-38\n",
            "Epoch 2/20, Steps 399/600, d_loss: 4.451493623491842e-06, g_loss: 98.19325256347656, D(x): 0.9999955296516418, G(x): 1.1559416409859933e-37\n",
            "Epoch 2/20, Steps 599/600, d_loss: 2.002720407290326e-07, g_loss: 97.14568328857422, D(x): 0.9999997615814209, G(x): 1.3931237374994547e-37\n",
            "Epoch 3/20, Steps 199/600, d_loss: 2.6345298920205096e-07, g_loss: 97.53262329101562, D(x): 0.9999997615814209, G(x): 4.427731522913683e-38\n",
            "Epoch 3/20, Steps 399/600, d_loss: 9.059912287057159e-08, g_loss: 96.74192810058594, D(x): 1.0, G(x): 2.2319038358090163e-38\n",
            "Epoch 3/20, Steps 599/600, d_loss: 1.4901195299898973e-07, g_loss: 97.73165893554688, D(x): 0.9999998211860657, G(x): 2.7257308874147006e-37\n",
            "Epoch 4/20, Steps 199/600, d_loss: 2.3484319910949125e-07, g_loss: 97.73214721679688, D(x): 0.9999997615814209, G(x): 4.2294578795606645e-38\n",
            "Epoch 4/20, Steps 399/600, d_loss: 2.3722779474155686e-07, g_loss: 98.22306060791016, D(x): 0.9999997615814209, G(x): 9.524038237699537e-38\n",
            "Epoch 4/20, Steps 599/600, d_loss: 2.2411454381199292e-07, g_loss: 97.38567352294922, D(x): 0.9999998211860657, G(x): 3.7237901361911283e-37\n",
            "Epoch 5/20, Steps 199/600, d_loss: 7.152564762691327e-08, g_loss: 98.11507415771484, D(x): 1.0, G(x): 9.024601452029529e-38\n",
            "Epoch 5/20, Steps 399/600, d_loss: 7.510194421911365e-08, g_loss: 96.75384521484375, D(x): 0.9999998807907104, G(x): 8.161549687227151e-37\n",
            "Epoch 5/20, Steps 599/600, d_loss: 8.821495356414744e-08, g_loss: 96.18781280517578, D(x): 0.9999998807907104, G(x): 7.758144333732831e-38\n",
            "Epoch 6/20, Steps 199/600, d_loss: 3.373671972894954e-07, g_loss: 96.44473266601562, D(x): 0.9999997019767761, G(x): 1.3280959777950144e-36\n",
            "Epoch 6/20, Steps 399/600, d_loss: 8.583083399571478e-08, g_loss: 96.23554229736328, D(x): 0.9999998807907104, G(x): 8.176706131417288e-36\n",
            "Epoch 6/20, Steps 599/600, d_loss: 9.095994641938887e-07, g_loss: 95.47843170166016, D(x): 0.9999990463256836, G(x): 2.7425895168754225e-37\n",
            "Epoch 7/20, Steps 199/600, d_loss: 1.0013592799396065e-07, g_loss: 96.15692901611328, D(x): 0.9999998807907104, G(x): 2.0825425153532555e-37\n",
            "Epoch 7/20, Steps 399/600, d_loss: 4.589610682614875e-07, g_loss: 96.3497085571289, D(x): 0.9999995231628418, G(x): 7.428888071906935e-37\n",
            "Epoch 7/20, Steps 599/600, d_loss: 4.8875829605776744e-08, g_loss: 95.54925537109375, D(x): 1.0, G(x): 4.797381838479961e-37\n",
            "Epoch 8/20, Steps 199/600, d_loss: 4.506202060383657e-07, g_loss: 96.7134780883789, D(x): 0.9999995231628418, G(x): 2.58855206344421e-37\n",
            "Epoch 8/20, Steps 399/600, d_loss: 5.6028437001032216e-08, g_loss: 94.8524398803711, D(x): 0.9999998807907104, G(x): 1.4083319153868172e-35\n",
            "Epoch 8/20, Steps 599/600, d_loss: 7.152558545442389e-09, g_loss: 96.25028228759766, D(x): 1.0, G(x): 5.1941977260756396e-37\n",
            "Epoch 9/20, Steps 199/600, d_loss: 1.1563324164853839e-07, g_loss: 95.97039031982422, D(x): 0.9999998211860657, G(x): 1.2600500005646219e-36\n",
            "Epoch 9/20, Steps 399/600, d_loss: 1.1563356139276948e-07, g_loss: 95.29412078857422, D(x): 0.9999998211860657, G(x): 3.9106132653247016e-37\n",
            "Epoch 9/20, Steps 599/600, d_loss: 3.099442835718946e-08, g_loss: 95.553955078125, D(x): 1.0, G(x): 1.0265873089078854e-36\n",
            "Epoch 10/20, Steps 199/600, d_loss: 2.3841861818141297e-08, g_loss: 93.90723419189453, D(x): 1.0, G(x): 1.9041037248745323e-36\n",
            "Epoch 10/20, Steps 399/600, d_loss: 4.291536725986589e-08, g_loss: 96.93183135986328, D(x): 1.0, G(x): 3.7295359083103686e-37\n",
            "Epoch 10/20, Steps 599/600, d_loss: 1.2159370044173556e-07, g_loss: 94.65765380859375, D(x): 0.9999998807907104, G(x): 5.228765539533765e-36\n",
            "Epoch 11/20, Steps 199/600, d_loss: 5.960465454535324e-09, g_loss: 95.99781036376953, D(x): 1.0, G(x): 4.0189774468121986e-36\n",
            "Epoch 11/20, Steps 399/600, d_loss: 2.3841861818141297e-08, g_loss: 95.5680160522461, D(x): 1.0, G(x): 4.036026563180967e-37\n",
            "Epoch 11/20, Steps 599/600, d_loss: 3.5762792727211945e-09, g_loss: 95.47956085205078, D(x): 1.0, G(x): 3.0825595910817116e-36\n",
            "Epoch 12/20, Steps 199/600, d_loss: 1.0252031756863289e-07, g_loss: 94.21578216552734, D(x): 0.9999998807907104, G(x): 1.7315297608325784e-36\n",
            "Epoch 12/20, Steps 399/600, d_loss: 4.7683719195390495e-09, g_loss: 94.57728576660156, D(x): 1.0, G(x): 6.129027545187407e-35\n",
            "Epoch 12/20, Steps 599/600, d_loss: 2.1457688959003463e-08, g_loss: 93.24708557128906, D(x): 1.0, G(x): 1.0209253384725513e-34\n",
            "Epoch 13/20, Steps 199/600, d_loss: 9.536745615434938e-09, g_loss: 94.08428192138672, D(x): 1.0, G(x): 9.641625070635181e-35\n",
            "Epoch 13/20, Steps 399/600, d_loss: 1.3113023555888503e-08, g_loss: 94.3369140625, D(x): 1.0, G(x): 6.194809770262857e-34\n",
            "Epoch 13/20, Steps 599/600, d_loss: 3.5762792727211945e-09, g_loss: 96.12007904052734, D(x): 1.0, G(x): 1.16371617939072e-36\n",
            "Epoch 14/20, Steps 199/600, d_loss: 3.218654143211097e-08, g_loss: 93.28160095214844, D(x): 1.0, G(x): 1.265512996483163e-34\n",
            "Epoch 14/20, Steps 399/600, d_loss: 1.0371251590868269e-07, g_loss: 94.2995376586914, D(x): 0.9999998807907104, G(x): 4.3571584328223394e-36\n",
            "Epoch 14/20, Steps 599/600, d_loss: 2.5613221213685517e-35, g_loss: 93.52225494384766, D(x): 1.0, G(x): 2.5613221213685517e-35\n",
            "Epoch 15/20, Steps 199/600, d_loss: 3.5762792727211945e-09, g_loss: 95.36112976074219, D(x): 1.0, G(x): 2.786184921035462e-36\n",
            "Epoch 15/20, Steps 399/600, d_loss: 2.419977533918427e-07, g_loss: 93.10909271240234, D(x): 0.9999997615814209, G(x): 4.929104952387094e-35\n",
            "Epoch 15/20, Steps 599/600, d_loss: 2.7418167292125872e-08, g_loss: 93.93663787841797, D(x): 1.0, G(x): 8.139398391581993e-35\n",
            "Epoch 16/20, Steps 199/600, d_loss: 5.960465454535324e-09, g_loss: 90.97576141357422, D(x): 1.0, G(x): 3.996223408977022e-36\n",
            "Epoch 16/20, Steps 399/600, d_loss: 1.5497212402237892e-08, g_loss: 93.0048828125, D(x): 1.0, G(x): 1.5517828346955937e-34\n",
            "Epoch 16/20, Steps 599/600, d_loss: 3.5762792727211945e-09, g_loss: 94.02616882324219, D(x): 1.0, G(x): 4.404977462657731e-36\n",
            "Epoch 17/20, Steps 199/600, d_loss: 1.6689304160877327e-08, g_loss: 94.12464904785156, D(x): 1.0, G(x): 1.0193631707651558e-33\n",
            "Epoch 17/20, Steps 399/600, d_loss: 3.5762792727211945e-09, g_loss: 93.2669906616211, D(x): 1.0, G(x): 3.2147557259532156e-34\n",
            "Epoch 17/20, Steps 599/600, d_loss: 1.1920929798847624e-09, g_loss: 94.66163635253906, D(x): 1.0, G(x): 2.410492593025184e-33\n",
            "Epoch 18/20, Steps 199/600, d_loss: 1.1920929798847624e-09, g_loss: 93.29923248291016, D(x): 1.0, G(x): 2.5115042345620964e-35\n",
            "Epoch 18/20, Steps 399/600, d_loss: 3.5762792727211945e-09, g_loss: 92.23135375976562, D(x): 1.0, G(x): 3.64205257164911e-35\n",
            "Epoch 18/20, Steps 599/600, d_loss: 1.1920929798847624e-09, g_loss: 94.11949157714844, D(x): 1.0, G(x): 4.852511278732074e-35\n",
            "Epoch 19/20, Steps 199/600, d_loss: 1.1920929798847624e-09, g_loss: 92.28054809570312, D(x): 1.0, G(x): 1.2976299357882761e-34\n",
            "Epoch 19/20, Steps 399/600, d_loss: 1.0728838262252793e-08, g_loss: 93.16285705566406, D(x): 1.0, G(x): 9.576886068097494e-36\n",
            "Epoch 19/20, Steps 599/600, d_loss: 9.536745615434938e-09, g_loss: 93.30955505371094, D(x): 1.0, G(x): 4.557335348896612e-35\n"
          ]
        }
      ]
    }
  ]
}