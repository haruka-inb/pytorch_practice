{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN6Euueh1iKnLcYi7wkvJI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haruka-inb/pytorch_practice/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Autoencoder"
      ],
      "metadata": {
        "id": "EOpiaYe9UiMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACr0axOOUeLi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "image_size = 784\n",
        "h_dim = 400\n",
        "z_dim = 20\n",
        "num_epochs = 15\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "dir = 'sample_dir'\n",
        "\n",
        "# Create a dictionary if not exists\n",
        "if not os.path.exists(dir):\n",
        "  os.mkdir(dir)\n",
        "\n",
        "# Download MNIST-dataset\n",
        "mnist = torchvision.datasets.MNIST(root='/../../data', train=True,\n",
        "                                   transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# Create a data loader\n",
        "data_loader = torch.utils.data.DataLoader(mnist, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "R8j95OJ5UqI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972197ac-6e79-4c98-ef46-364ecb6bd0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 159874606.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /../../data/MNIST/raw/train-images-idx3-ubyte.gz to /../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28112251.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /../../data/MNIST/raw/train-labels-idx1-ubyte.gz to /../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 51745513.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to /../../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4175915.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /../../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
        "    super(VAE, self).__init__()\n",
        "    self.fc1 = nn.Linear(image_size, h_dim)\n",
        "    self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "    self.fc3 = nn.Linear(h_dim, z_dim)\n",
        "    self.fc4 = nn.Linear(z_dim, h_dim)\n",
        "    self.fc5 = nn.Linear(h_dim, image_size)\n",
        "\n",
        "  def encoder(self, x):\n",
        "    h = F.relu(self.fc1(x))\n",
        "    return self.fc2(h), self.fc3(h)\n",
        "\n",
        "  def reparameterize(self, mu, log_var):\n",
        "    std = torch.exp(log_var/2)\n",
        "    eps = torch.rand_like(std)\n",
        "    return mu + std * eps\n",
        "\n",
        "  def decode(self, z):\n",
        "    h = F.relu(self.fc4(z))\n",
        "    return F.sigmoid(self.fc5(h))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, log_var = self.encoder(x)\n",
        "    z = self.reparameterize(mu, log_var)\n",
        "    x_reconst = self.decode(z)\n",
        "    return x_reconst, mu, log_var\n",
        "\n",
        "# Transfer the model to GPU\n",
        "model = VAE().to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "criteria = nn.BCELoss(size_average=False)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "XKoWxvGYVHJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a6851e-e769-4d39-b9d5-48287f15adfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
              "  (fc2): Linear(in_features=400, out_features=20, bias=True)\n",
              "  (fc3): Linear(in_features=400, out_features=20, bias=True)\n",
              "  (fc4): Linear(in_features=20, out_features=400, bias=True)\n",
              "  (fc5): Linear(in_features=400, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "for e in range(num_epochs):\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "\n",
        "    # Forward pass\n",
        "    images = images.to(device).view(-1, image_size)\n",
        "    x_reconst, mu, log_var = model(images)\n",
        "\n",
        "    # Compute reconstruction loss\n",
        "    # reconstruction loss ensures how the model could reconstruct input images well\n",
        "    # KL Divergent ensures distributions exists in the fixed latenet space\n",
        "    reconst_loss = criteria(x_reconst, images)\n",
        "    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # this is from VAE papar\n",
        "\n",
        "    # Backpropagate loss and optimize weights\n",
        "    loss = reconst_loss + kl_div\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print epoch, step, losses\n",
        "    if (i+1) % 10 == 0:\n",
        "      print(f\"Epoch {e+1}/{num_epochs}, Step {i+1}/{len(data_loader)}, Reconstruction Loss: {reconst_loss.item()}, KL Divergent: {kl_div.item()}\")\n"
      ],
      "metadata": {
        "id": "5Dqyw58GVPYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcae8e98-2f00-4413-8473-dae33f85f976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Step 10/469, Reconstruction Loss: 35250.26953125, KL Divergent: 4252.22021484375\n",
            "Epoch 1/15, Step 20/469, Reconstruction Loss: 29001.24609375, KL Divergent: 1044.8369140625\n",
            "Epoch 1/15, Step 30/469, Reconstruction Loss: 26795.5390625, KL Divergent: 755.898681640625\n",
            "Epoch 1/15, Step 40/469, Reconstruction Loss: 26114.56640625, KL Divergent: 307.8574523925781\n",
            "Epoch 1/15, Step 50/469, Reconstruction Loss: 25770.65234375, KL Divergent: 282.0201721191406\n",
            "Epoch 1/15, Step 60/469, Reconstruction Loss: 25286.4140625, KL Divergent: 386.7532958984375\n",
            "Epoch 1/15, Step 70/469, Reconstruction Loss: 22861.359375, KL Divergent: 474.0303955078125\n",
            "Epoch 1/15, Step 80/469, Reconstruction Loss: 21247.828125, KL Divergent: 643.3482666015625\n",
            "Epoch 1/15, Step 90/469, Reconstruction Loss: 20646.951171875, KL Divergent: 716.7455444335938\n",
            "Epoch 1/15, Step 100/469, Reconstruction Loss: 19290.17578125, KL Divergent: 669.1046142578125\n",
            "Epoch 1/15, Step 110/469, Reconstruction Loss: 19173.328125, KL Divergent: 758.8040771484375\n",
            "Epoch 1/15, Step 120/469, Reconstruction Loss: 17904.01953125, KL Divergent: 842.7376708984375\n",
            "Epoch 1/15, Step 130/469, Reconstruction Loss: 17705.49609375, KL Divergent: 826.7388916015625\n",
            "Epoch 1/15, Step 140/469, Reconstruction Loss: 18472.263671875, KL Divergent: 812.0817260742188\n",
            "Epoch 1/15, Step 150/469, Reconstruction Loss: 16867.5859375, KL Divergent: 821.06201171875\n",
            "Epoch 1/15, Step 160/469, Reconstruction Loss: 16467.916015625, KL Divergent: 834.9208984375\n",
            "Epoch 1/15, Step 170/469, Reconstruction Loss: 15899.673828125, KL Divergent: 943.0382690429688\n",
            "Epoch 1/15, Step 180/469, Reconstruction Loss: 16337.73046875, KL Divergent: 940.6973876953125\n",
            "Epoch 1/15, Step 190/469, Reconstruction Loss: 15425.37109375, KL Divergent: 975.873046875\n",
            "Epoch 1/15, Step 200/469, Reconstruction Loss: 14904.146484375, KL Divergent: 947.929443359375\n",
            "Epoch 1/15, Step 210/469, Reconstruction Loss: 15549.0576171875, KL Divergent: 934.0746459960938\n",
            "Epoch 1/15, Step 220/469, Reconstruction Loss: 15591.51953125, KL Divergent: 974.0191650390625\n",
            "Epoch 1/15, Step 230/469, Reconstruction Loss: 14497.248046875, KL Divergent: 957.9275512695312\n",
            "Epoch 1/15, Step 240/469, Reconstruction Loss: 14632.7119140625, KL Divergent: 1033.3123779296875\n",
            "Epoch 1/15, Step 250/469, Reconstruction Loss: 15286.3359375, KL Divergent: 1001.4857788085938\n",
            "Epoch 1/15, Step 260/469, Reconstruction Loss: 14316.8359375, KL Divergent: 949.7040405273438\n",
            "Epoch 1/15, Step 270/469, Reconstruction Loss: 14552.2265625, KL Divergent: 1079.064208984375\n",
            "Epoch 1/15, Step 280/469, Reconstruction Loss: 14802.0810546875, KL Divergent: 1039.037109375\n",
            "Epoch 1/15, Step 290/469, Reconstruction Loss: 14686.73828125, KL Divergent: 1016.8311157226562\n",
            "Epoch 1/15, Step 300/469, Reconstruction Loss: 14018.390625, KL Divergent: 1036.1666259765625\n",
            "Epoch 1/15, Step 310/469, Reconstruction Loss: 14012.5625, KL Divergent: 1115.138671875\n",
            "Epoch 1/15, Step 320/469, Reconstruction Loss: 13354.662109375, KL Divergent: 1044.8203125\n",
            "Epoch 1/15, Step 330/469, Reconstruction Loss: 13192.26953125, KL Divergent: 1103.111083984375\n",
            "Epoch 1/15, Step 340/469, Reconstruction Loss: 14153.328125, KL Divergent: 1060.7838134765625\n",
            "Epoch 1/15, Step 350/469, Reconstruction Loss: 14113.220703125, KL Divergent: 1060.53125\n",
            "Epoch 1/15, Step 360/469, Reconstruction Loss: 13382.2099609375, KL Divergent: 1116.08544921875\n",
            "Epoch 1/15, Step 370/469, Reconstruction Loss: 14631.388671875, KL Divergent: 1104.2371826171875\n",
            "Epoch 1/15, Step 380/469, Reconstruction Loss: 12828.275390625, KL Divergent: 1091.1036376953125\n",
            "Epoch 1/15, Step 390/469, Reconstruction Loss: 13105.267578125, KL Divergent: 1036.7158203125\n",
            "Epoch 1/15, Step 400/469, Reconstruction Loss: 12697.1044921875, KL Divergent: 1114.7587890625\n",
            "Epoch 1/15, Step 410/469, Reconstruction Loss: 13243.658203125, KL Divergent: 1059.085205078125\n",
            "Epoch 1/15, Step 420/469, Reconstruction Loss: 12000.5146484375, KL Divergent: 1049.3087158203125\n",
            "Epoch 1/15, Step 430/469, Reconstruction Loss: 13353.849609375, KL Divergent: 1117.015625\n",
            "Epoch 1/15, Step 440/469, Reconstruction Loss: 13021.5546875, KL Divergent: 1141.736328125\n",
            "Epoch 1/15, Step 450/469, Reconstruction Loss: 12959.302734375, KL Divergent: 1125.231689453125\n",
            "Epoch 1/15, Step 460/469, Reconstruction Loss: 12984.857421875, KL Divergent: 1185.258056640625\n",
            "Epoch 2/15, Step 10/469, Reconstruction Loss: 12071.58203125, KL Divergent: 1208.564697265625\n",
            "Epoch 2/15, Step 20/469, Reconstruction Loss: 12763.361328125, KL Divergent: 1164.588134765625\n",
            "Epoch 2/15, Step 30/469, Reconstruction Loss: 12389.611328125, KL Divergent: 1195.66796875\n",
            "Epoch 2/15, Step 40/469, Reconstruction Loss: 12843.357421875, KL Divergent: 1152.2618408203125\n",
            "Epoch 2/15, Step 50/469, Reconstruction Loss: 12539.4609375, KL Divergent: 1166.9656982421875\n",
            "Epoch 2/15, Step 60/469, Reconstruction Loss: 12413.0859375, KL Divergent: 1160.4197998046875\n",
            "Epoch 2/15, Step 70/469, Reconstruction Loss: 12525.9091796875, KL Divergent: 1151.753662109375\n",
            "Epoch 2/15, Step 80/469, Reconstruction Loss: 11990.216796875, KL Divergent: 1123.384765625\n",
            "Epoch 2/15, Step 90/469, Reconstruction Loss: 12873.203125, KL Divergent: 1237.224853515625\n",
            "Epoch 2/15, Step 100/469, Reconstruction Loss: 12339.09375, KL Divergent: 1246.253662109375\n",
            "Epoch 2/15, Step 110/469, Reconstruction Loss: 12235.9814453125, KL Divergent: 1152.95751953125\n",
            "Epoch 2/15, Step 120/469, Reconstruction Loss: 11755.341796875, KL Divergent: 1144.205078125\n",
            "Epoch 2/15, Step 130/469, Reconstruction Loss: 12192.255859375, KL Divergent: 1169.197998046875\n",
            "Epoch 2/15, Step 140/469, Reconstruction Loss: 12167.0400390625, KL Divergent: 1167.849365234375\n",
            "Epoch 2/15, Step 150/469, Reconstruction Loss: 12048.970703125, KL Divergent: 1141.5914306640625\n",
            "Epoch 2/15, Step 160/469, Reconstruction Loss: 12187.689453125, KL Divergent: 1139.58935546875\n",
            "Epoch 2/15, Step 170/469, Reconstruction Loss: 12468.908203125, KL Divergent: 1162.86572265625\n",
            "Epoch 2/15, Step 180/469, Reconstruction Loss: 12034.712890625, KL Divergent: 1191.613525390625\n",
            "Epoch 2/15, Step 190/469, Reconstruction Loss: 11750.6640625, KL Divergent: 1211.3367919921875\n",
            "Epoch 2/15, Step 200/469, Reconstruction Loss: 11999.7861328125, KL Divergent: 1136.860107421875\n",
            "Epoch 2/15, Step 210/469, Reconstruction Loss: 12046.2607421875, KL Divergent: 1193.782470703125\n",
            "Epoch 2/15, Step 220/469, Reconstruction Loss: 12369.326171875, KL Divergent: 1236.6500244140625\n",
            "Epoch 2/15, Step 230/469, Reconstruction Loss: 11888.650390625, KL Divergent: 1201.8968505859375\n",
            "Epoch 2/15, Step 240/469, Reconstruction Loss: 12164.76953125, KL Divergent: 1301.329345703125\n",
            "Epoch 2/15, Step 250/469, Reconstruction Loss: 11448.0390625, KL Divergent: 1199.7803955078125\n",
            "Epoch 2/15, Step 260/469, Reconstruction Loss: 12029.970703125, KL Divergent: 1190.154296875\n",
            "Epoch 2/15, Step 270/469, Reconstruction Loss: 11737.8046875, KL Divergent: 1146.307373046875\n",
            "Epoch 2/15, Step 280/469, Reconstruction Loss: 12153.09765625, KL Divergent: 1231.79150390625\n",
            "Epoch 2/15, Step 290/469, Reconstruction Loss: 11912.5, KL Divergent: 1192.6162109375\n",
            "Epoch 2/15, Step 300/469, Reconstruction Loss: 11355.2197265625, KL Divergent: 1232.37109375\n",
            "Epoch 2/15, Step 310/469, Reconstruction Loss: 11396.548828125, KL Divergent: 1242.9053955078125\n",
            "Epoch 2/15, Step 320/469, Reconstruction Loss: 11509.5390625, KL Divergent: 1206.398193359375\n",
            "Epoch 2/15, Step 330/469, Reconstruction Loss: 11528.8046875, KL Divergent: 1244.51513671875\n",
            "Epoch 2/15, Step 340/469, Reconstruction Loss: 12256.5146484375, KL Divergent: 1235.73388671875\n",
            "Epoch 2/15, Step 350/469, Reconstruction Loss: 11444.7880859375, KL Divergent: 1218.54736328125\n",
            "Epoch 2/15, Step 360/469, Reconstruction Loss: 11590.31640625, KL Divergent: 1150.614013671875\n",
            "Epoch 2/15, Step 370/469, Reconstruction Loss: 11236.3427734375, KL Divergent: 1241.59912109375\n",
            "Epoch 2/15, Step 380/469, Reconstruction Loss: 11844.3515625, KL Divergent: 1223.8297119140625\n",
            "Epoch 2/15, Step 390/469, Reconstruction Loss: 11311.845703125, KL Divergent: 1232.919189453125\n",
            "Epoch 2/15, Step 400/469, Reconstruction Loss: 12080.751953125, KL Divergent: 1183.7503662109375\n",
            "Epoch 2/15, Step 410/469, Reconstruction Loss: 11646.1484375, KL Divergent: 1221.116455078125\n",
            "Epoch 2/15, Step 420/469, Reconstruction Loss: 11782.59375, KL Divergent: 1221.1611328125\n",
            "Epoch 2/15, Step 430/469, Reconstruction Loss: 10949.7353515625, KL Divergent: 1200.494873046875\n",
            "Epoch 2/15, Step 440/469, Reconstruction Loss: 11912.529296875, KL Divergent: 1216.263427734375\n",
            "Epoch 2/15, Step 450/469, Reconstruction Loss: 10716.0517578125, KL Divergent: 1252.1585693359375\n",
            "Epoch 2/15, Step 460/469, Reconstruction Loss: 10991.6396484375, KL Divergent: 1166.9281005859375\n",
            "Epoch 3/15, Step 10/469, Reconstruction Loss: 11241.28125, KL Divergent: 1256.173583984375\n",
            "Epoch 3/15, Step 20/469, Reconstruction Loss: 10858.2490234375, KL Divergent: 1236.91015625\n",
            "Epoch 3/15, Step 30/469, Reconstruction Loss: 11918.328125, KL Divergent: 1298.021484375\n",
            "Epoch 3/15, Step 40/469, Reconstruction Loss: 10644.314453125, KL Divergent: 1245.5054931640625\n",
            "Epoch 3/15, Step 50/469, Reconstruction Loss: 11443.91015625, KL Divergent: 1276.58740234375\n",
            "Epoch 3/15, Step 60/469, Reconstruction Loss: 11694.126953125, KL Divergent: 1237.2821044921875\n",
            "Epoch 3/15, Step 70/469, Reconstruction Loss: 11468.748046875, KL Divergent: 1261.891845703125\n",
            "Epoch 3/15, Step 80/469, Reconstruction Loss: 11447.642578125, KL Divergent: 1234.952392578125\n",
            "Epoch 3/15, Step 90/469, Reconstruction Loss: 11249.24609375, KL Divergent: 1234.817138671875\n",
            "Epoch 3/15, Step 100/469, Reconstruction Loss: 10955.3154296875, KL Divergent: 1225.220458984375\n",
            "Epoch 3/15, Step 110/469, Reconstruction Loss: 11461.271484375, KL Divergent: 1271.3505859375\n",
            "Epoch 3/15, Step 120/469, Reconstruction Loss: 11078.080078125, KL Divergent: 1300.305908203125\n",
            "Epoch 3/15, Step 130/469, Reconstruction Loss: 11369.787109375, KL Divergent: 1265.943359375\n",
            "Epoch 3/15, Step 140/469, Reconstruction Loss: 10799.66796875, KL Divergent: 1167.366943359375\n",
            "Epoch 3/15, Step 150/469, Reconstruction Loss: 11349.84765625, KL Divergent: 1331.14697265625\n",
            "Epoch 3/15, Step 160/469, Reconstruction Loss: 11430.2666015625, KL Divergent: 1281.2119140625\n",
            "Epoch 3/15, Step 170/469, Reconstruction Loss: 11501.853515625, KL Divergent: 1247.904296875\n",
            "Epoch 3/15, Step 180/469, Reconstruction Loss: 11144.4453125, KL Divergent: 1237.6893310546875\n",
            "Epoch 3/15, Step 190/469, Reconstruction Loss: 11435.810546875, KL Divergent: 1235.015869140625\n",
            "Epoch 3/15, Step 200/469, Reconstruction Loss: 11122.23046875, KL Divergent: 1233.3970947265625\n",
            "Epoch 3/15, Step 210/469, Reconstruction Loss: 10950.83984375, KL Divergent: 1180.92724609375\n",
            "Epoch 3/15, Step 220/469, Reconstruction Loss: 10894.3017578125, KL Divergent: 1236.58935546875\n",
            "Epoch 3/15, Step 230/469, Reconstruction Loss: 10906.6171875, KL Divergent: 1239.984619140625\n",
            "Epoch 3/15, Step 240/469, Reconstruction Loss: 11178.63671875, KL Divergent: 1272.3720703125\n",
            "Epoch 3/15, Step 250/469, Reconstruction Loss: 11105.158203125, KL Divergent: 1252.358642578125\n",
            "Epoch 3/15, Step 260/469, Reconstruction Loss: 10461.2734375, KL Divergent: 1202.0257568359375\n",
            "Epoch 3/15, Step 270/469, Reconstruction Loss: 10876.61328125, KL Divergent: 1262.5511474609375\n",
            "Epoch 3/15, Step 280/469, Reconstruction Loss: 11072.08984375, KL Divergent: 1296.925537109375\n",
            "Epoch 3/15, Step 290/469, Reconstruction Loss: 11133.66796875, KL Divergent: 1267.653076171875\n",
            "Epoch 3/15, Step 300/469, Reconstruction Loss: 10966.21484375, KL Divergent: 1209.084228515625\n",
            "Epoch 3/15, Step 310/469, Reconstruction Loss: 10669.75390625, KL Divergent: 1259.56201171875\n",
            "Epoch 3/15, Step 320/469, Reconstruction Loss: 10434.482421875, KL Divergent: 1214.205078125\n",
            "Epoch 3/15, Step 330/469, Reconstruction Loss: 11036.6953125, KL Divergent: 1314.654541015625\n",
            "Epoch 3/15, Step 340/469, Reconstruction Loss: 10878.640625, KL Divergent: 1296.669189453125\n",
            "Epoch 3/15, Step 350/469, Reconstruction Loss: 11202.7998046875, KL Divergent: 1257.192626953125\n",
            "Epoch 3/15, Step 360/469, Reconstruction Loss: 11339.298828125, KL Divergent: 1272.647216796875\n",
            "Epoch 3/15, Step 370/469, Reconstruction Loss: 10558.71875, KL Divergent: 1230.622802734375\n",
            "Epoch 3/15, Step 380/469, Reconstruction Loss: 10435.78515625, KL Divergent: 1227.3092041015625\n",
            "Epoch 3/15, Step 390/469, Reconstruction Loss: 10963.775390625, KL Divergent: 1241.3223876953125\n",
            "Epoch 3/15, Step 400/469, Reconstruction Loss: 11118.248046875, KL Divergent: 1276.85498046875\n",
            "Epoch 3/15, Step 410/469, Reconstruction Loss: 10818.556640625, KL Divergent: 1253.1307373046875\n",
            "Epoch 3/15, Step 420/469, Reconstruction Loss: 10289.390625, KL Divergent: 1204.214599609375\n",
            "Epoch 3/15, Step 430/469, Reconstruction Loss: 11229.126953125, KL Divergent: 1297.37841796875\n",
            "Epoch 3/15, Step 440/469, Reconstruction Loss: 10981.517578125, KL Divergent: 1236.3466796875\n",
            "Epoch 3/15, Step 450/469, Reconstruction Loss: 11238.580078125, KL Divergent: 1247.03076171875\n",
            "Epoch 3/15, Step 460/469, Reconstruction Loss: 11167.75, KL Divergent: 1291.50927734375\n",
            "Epoch 4/15, Step 10/469, Reconstruction Loss: 10721.73828125, KL Divergent: 1253.91552734375\n",
            "Epoch 4/15, Step 20/469, Reconstruction Loss: 11180.3408203125, KL Divergent: 1264.758056640625\n",
            "Epoch 4/15, Step 30/469, Reconstruction Loss: 11090.748046875, KL Divergent: 1262.16748046875\n",
            "Epoch 4/15, Step 40/469, Reconstruction Loss: 11073.2470703125, KL Divergent: 1276.2396240234375\n",
            "Epoch 4/15, Step 50/469, Reconstruction Loss: 10595.921875, KL Divergent: 1318.4371337890625\n",
            "Epoch 4/15, Step 60/469, Reconstruction Loss: 10691.572265625, KL Divergent: 1281.26025390625\n",
            "Epoch 4/15, Step 70/469, Reconstruction Loss: 10716.095703125, KL Divergent: 1273.833251953125\n",
            "Epoch 4/15, Step 80/469, Reconstruction Loss: 10433.912109375, KL Divergent: 1304.962646484375\n",
            "Epoch 4/15, Step 90/469, Reconstruction Loss: 9849.935546875, KL Divergent: 1223.0631103515625\n",
            "Epoch 4/15, Step 100/469, Reconstruction Loss: 10142.3466796875, KL Divergent: 1253.520751953125\n",
            "Epoch 4/15, Step 110/469, Reconstruction Loss: 10399.162109375, KL Divergent: 1277.2919921875\n",
            "Epoch 4/15, Step 120/469, Reconstruction Loss: 10746.162109375, KL Divergent: 1310.462158203125\n",
            "Epoch 4/15, Step 130/469, Reconstruction Loss: 10552.33203125, KL Divergent: 1271.60595703125\n",
            "Epoch 4/15, Step 140/469, Reconstruction Loss: 10868.75, KL Divergent: 1317.3897705078125\n",
            "Epoch 4/15, Step 150/469, Reconstruction Loss: 10273.0390625, KL Divergent: 1299.671630859375\n",
            "Epoch 4/15, Step 160/469, Reconstruction Loss: 10581.8232421875, KL Divergent: 1289.1864013671875\n",
            "Epoch 4/15, Step 170/469, Reconstruction Loss: 10794.10546875, KL Divergent: 1256.8486328125\n",
            "Epoch 4/15, Step 180/469, Reconstruction Loss: 10429.580078125, KL Divergent: 1269.004638671875\n",
            "Epoch 4/15, Step 190/469, Reconstruction Loss: 10750.98828125, KL Divergent: 1285.94091796875\n",
            "Epoch 4/15, Step 200/469, Reconstruction Loss: 11486.349609375, KL Divergent: 1305.432373046875\n",
            "Epoch 4/15, Step 210/469, Reconstruction Loss: 10625.9140625, KL Divergent: 1245.506591796875\n",
            "Epoch 4/15, Step 220/469, Reconstruction Loss: 11252.861328125, KL Divergent: 1283.405517578125\n",
            "Epoch 4/15, Step 230/469, Reconstruction Loss: 10546.166015625, KL Divergent: 1289.7294921875\n",
            "Epoch 4/15, Step 240/469, Reconstruction Loss: 10544.69140625, KL Divergent: 1237.599365234375\n",
            "Epoch 4/15, Step 250/469, Reconstruction Loss: 10639.3349609375, KL Divergent: 1278.5867919921875\n",
            "Epoch 4/15, Step 260/469, Reconstruction Loss: 10628.3359375, KL Divergent: 1270.5982666015625\n",
            "Epoch 4/15, Step 270/469, Reconstruction Loss: 10692.154296875, KL Divergent: 1309.1756591796875\n",
            "Epoch 4/15, Step 280/469, Reconstruction Loss: 10571.37890625, KL Divergent: 1282.26220703125\n",
            "Epoch 4/15, Step 290/469, Reconstruction Loss: 10960.21875, KL Divergent: 1293.3172607421875\n",
            "Epoch 4/15, Step 300/469, Reconstruction Loss: 11026.474609375, KL Divergent: 1233.2630615234375\n",
            "Epoch 4/15, Step 310/469, Reconstruction Loss: 10757.232421875, KL Divergent: 1299.32373046875\n",
            "Epoch 4/15, Step 320/469, Reconstruction Loss: 11026.515625, KL Divergent: 1236.294921875\n",
            "Epoch 4/15, Step 330/469, Reconstruction Loss: 10929.296875, KL Divergent: 1279.83837890625\n",
            "Epoch 4/15, Step 340/469, Reconstruction Loss: 11046.37109375, KL Divergent: 1232.478271484375\n",
            "Epoch 4/15, Step 350/469, Reconstruction Loss: 10631.7109375, KL Divergent: 1254.9736328125\n",
            "Epoch 4/15, Step 360/469, Reconstruction Loss: 10462.8232421875, KL Divergent: 1311.002197265625\n",
            "Epoch 4/15, Step 370/469, Reconstruction Loss: 10937.8974609375, KL Divergent: 1278.177001953125\n",
            "Epoch 4/15, Step 380/469, Reconstruction Loss: 10698.822265625, KL Divergent: 1255.8150634765625\n",
            "Epoch 4/15, Step 390/469, Reconstruction Loss: 10163.826171875, KL Divergent: 1291.102294921875\n",
            "Epoch 4/15, Step 400/469, Reconstruction Loss: 10518.302734375, KL Divergent: 1281.1641845703125\n",
            "Epoch 4/15, Step 410/469, Reconstruction Loss: 10582.0263671875, KL Divergent: 1266.1529541015625\n",
            "Epoch 4/15, Step 420/469, Reconstruction Loss: 10644.908203125, KL Divergent: 1217.692138671875\n",
            "Epoch 4/15, Step 430/469, Reconstruction Loss: 10085.669921875, KL Divergent: 1253.3863525390625\n",
            "Epoch 4/15, Step 440/469, Reconstruction Loss: 10646.26953125, KL Divergent: 1275.7877197265625\n",
            "Epoch 4/15, Step 450/469, Reconstruction Loss: 10614.244140625, KL Divergent: 1267.13037109375\n",
            "Epoch 4/15, Step 460/469, Reconstruction Loss: 10238.259765625, KL Divergent: 1174.401611328125\n",
            "Epoch 5/15, Step 10/469, Reconstruction Loss: 10361.255859375, KL Divergent: 1235.5609130859375\n",
            "Epoch 5/15, Step 20/469, Reconstruction Loss: 10693.7041015625, KL Divergent: 1290.4193115234375\n",
            "Epoch 5/15, Step 30/469, Reconstruction Loss: 11017.4267578125, KL Divergent: 1276.70263671875\n",
            "Epoch 5/15, Step 40/469, Reconstruction Loss: 10316.556640625, KL Divergent: 1285.849609375\n",
            "Epoch 5/15, Step 50/469, Reconstruction Loss: 10635.357421875, KL Divergent: 1271.166015625\n",
            "Epoch 5/15, Step 60/469, Reconstruction Loss: 10307.810546875, KL Divergent: 1242.9141845703125\n",
            "Epoch 5/15, Step 70/469, Reconstruction Loss: 10569.685546875, KL Divergent: 1291.5478515625\n",
            "Epoch 5/15, Step 80/469, Reconstruction Loss: 10006.287109375, KL Divergent: 1302.18994140625\n",
            "Epoch 5/15, Step 90/469, Reconstruction Loss: 10138.166015625, KL Divergent: 1271.22265625\n",
            "Epoch 5/15, Step 100/469, Reconstruction Loss: 10211.6533203125, KL Divergent: 1245.1541748046875\n",
            "Epoch 5/15, Step 110/469, Reconstruction Loss: 10559.0546875, KL Divergent: 1293.85595703125\n",
            "Epoch 5/15, Step 120/469, Reconstruction Loss: 10173.392578125, KL Divergent: 1270.572265625\n",
            "Epoch 5/15, Step 130/469, Reconstruction Loss: 10249.8212890625, KL Divergent: 1291.161865234375\n",
            "Epoch 5/15, Step 140/469, Reconstruction Loss: 10644.1083984375, KL Divergent: 1240.49951171875\n",
            "Epoch 5/15, Step 150/469, Reconstruction Loss: 10480.83203125, KL Divergent: 1262.968017578125\n",
            "Epoch 5/15, Step 160/469, Reconstruction Loss: 10819.75, KL Divergent: 1276.84033203125\n",
            "Epoch 5/15, Step 170/469, Reconstruction Loss: 10608.3955078125, KL Divergent: 1358.94189453125\n",
            "Epoch 5/15, Step 180/469, Reconstruction Loss: 10316.455078125, KL Divergent: 1257.782958984375\n",
            "Epoch 5/15, Step 190/469, Reconstruction Loss: 10179.15234375, KL Divergent: 1334.967529296875\n",
            "Epoch 5/15, Step 200/469, Reconstruction Loss: 10158.791015625, KL Divergent: 1224.891357421875\n",
            "Epoch 5/15, Step 210/469, Reconstruction Loss: 10555.8359375, KL Divergent: 1297.729248046875\n",
            "Epoch 5/15, Step 220/469, Reconstruction Loss: 10435.79296875, KL Divergent: 1261.25\n",
            "Epoch 5/15, Step 230/469, Reconstruction Loss: 10183.37890625, KL Divergent: 1229.3824462890625\n",
            "Epoch 5/15, Step 240/469, Reconstruction Loss: 10199.30859375, KL Divergent: 1318.5494384765625\n",
            "Epoch 5/15, Step 250/469, Reconstruction Loss: 10392.9140625, KL Divergent: 1256.4375\n",
            "Epoch 5/15, Step 260/469, Reconstruction Loss: 10401.44140625, KL Divergent: 1308.2376708984375\n",
            "Epoch 5/15, Step 270/469, Reconstruction Loss: 10543.521484375, KL Divergent: 1279.0694580078125\n",
            "Epoch 5/15, Step 280/469, Reconstruction Loss: 10244.7939453125, KL Divergent: 1271.55615234375\n",
            "Epoch 5/15, Step 290/469, Reconstruction Loss: 10486.62890625, KL Divergent: 1312.03955078125\n",
            "Epoch 5/15, Step 300/469, Reconstruction Loss: 10359.921875, KL Divergent: 1276.363037109375\n",
            "Epoch 5/15, Step 310/469, Reconstruction Loss: 10977.9560546875, KL Divergent: 1312.19580078125\n",
            "Epoch 5/15, Step 320/469, Reconstruction Loss: 9966.763671875, KL Divergent: 1252.4793701171875\n",
            "Epoch 5/15, Step 330/469, Reconstruction Loss: 10170.20703125, KL Divergent: 1231.76416015625\n",
            "Epoch 5/15, Step 340/469, Reconstruction Loss: 10642.564453125, KL Divergent: 1276.1494140625\n",
            "Epoch 5/15, Step 350/469, Reconstruction Loss: 10298.51953125, KL Divergent: 1342.371826171875\n",
            "Epoch 5/15, Step 360/469, Reconstruction Loss: 10634.96875, KL Divergent: 1248.769287109375\n",
            "Epoch 5/15, Step 370/469, Reconstruction Loss: 10234.826171875, KL Divergent: 1258.298095703125\n",
            "Epoch 5/15, Step 380/469, Reconstruction Loss: 9925.619140625, KL Divergent: 1256.8477783203125\n",
            "Epoch 5/15, Step 390/469, Reconstruction Loss: 10114.271484375, KL Divergent: 1173.912841796875\n",
            "Epoch 5/15, Step 400/469, Reconstruction Loss: 10214.02734375, KL Divergent: 1305.018310546875\n",
            "Epoch 5/15, Step 410/469, Reconstruction Loss: 10485.3779296875, KL Divergent: 1287.6993408203125\n",
            "Epoch 5/15, Step 420/469, Reconstruction Loss: 10243.556640625, KL Divergent: 1296.626220703125\n",
            "Epoch 5/15, Step 430/469, Reconstruction Loss: 9980.21875, KL Divergent: 1252.530517578125\n",
            "Epoch 5/15, Step 440/469, Reconstruction Loss: 10525.572265625, KL Divergent: 1320.8818359375\n",
            "Epoch 5/15, Step 450/469, Reconstruction Loss: 9849.2197265625, KL Divergent: 1267.73828125\n",
            "Epoch 5/15, Step 460/469, Reconstruction Loss: 10420.638671875, KL Divergent: 1289.3546142578125\n",
            "Epoch 6/15, Step 10/469, Reconstruction Loss: 9733.626953125, KL Divergent: 1236.266845703125\n",
            "Epoch 6/15, Step 20/469, Reconstruction Loss: 10100.31640625, KL Divergent: 1303.6141357421875\n",
            "Epoch 6/15, Step 30/469, Reconstruction Loss: 10127.701171875, KL Divergent: 1238.411865234375\n",
            "Epoch 6/15, Step 40/469, Reconstruction Loss: 10231.1953125, KL Divergent: 1317.988525390625\n",
            "Epoch 6/15, Step 50/469, Reconstruction Loss: 10690.564453125, KL Divergent: 1260.513427734375\n",
            "Epoch 6/15, Step 60/469, Reconstruction Loss: 10380.61328125, KL Divergent: 1259.099365234375\n",
            "Epoch 6/15, Step 70/469, Reconstruction Loss: 10080.349609375, KL Divergent: 1251.8486328125\n",
            "Epoch 6/15, Step 80/469, Reconstruction Loss: 10064.416015625, KL Divergent: 1266.500244140625\n",
            "Epoch 6/15, Step 90/469, Reconstruction Loss: 10289.0029296875, KL Divergent: 1337.352783203125\n",
            "Epoch 6/15, Step 100/469, Reconstruction Loss: 10178.88671875, KL Divergent: 1324.8519287109375\n",
            "Epoch 6/15, Step 110/469, Reconstruction Loss: 10240.8583984375, KL Divergent: 1259.9388427734375\n",
            "Epoch 6/15, Step 120/469, Reconstruction Loss: 10031.966796875, KL Divergent: 1294.7247314453125\n",
            "Epoch 6/15, Step 130/469, Reconstruction Loss: 10254.423828125, KL Divergent: 1267.841552734375\n",
            "Epoch 6/15, Step 140/469, Reconstruction Loss: 10411.1953125, KL Divergent: 1281.183837890625\n",
            "Epoch 6/15, Step 150/469, Reconstruction Loss: 10760.263671875, KL Divergent: 1298.814208984375\n",
            "Epoch 6/15, Step 160/469, Reconstruction Loss: 10044.005859375, KL Divergent: 1294.356689453125\n",
            "Epoch 6/15, Step 170/469, Reconstruction Loss: 10111.5927734375, KL Divergent: 1216.0269775390625\n",
            "Epoch 6/15, Step 180/469, Reconstruction Loss: 9737.76953125, KL Divergent: 1270.7279052734375\n",
            "Epoch 6/15, Step 190/469, Reconstruction Loss: 10377.708984375, KL Divergent: 1267.78466796875\n",
            "Epoch 6/15, Step 200/469, Reconstruction Loss: 10235.3203125, KL Divergent: 1302.308349609375\n",
            "Epoch 6/15, Step 210/469, Reconstruction Loss: 10735.0546875, KL Divergent: 1284.202880859375\n",
            "Epoch 6/15, Step 220/469, Reconstruction Loss: 10191.705078125, KL Divergent: 1298.6923828125\n",
            "Epoch 6/15, Step 230/469, Reconstruction Loss: 10039.482421875, KL Divergent: 1243.132080078125\n",
            "Epoch 6/15, Step 240/469, Reconstruction Loss: 10384.59765625, KL Divergent: 1256.76025390625\n",
            "Epoch 6/15, Step 250/469, Reconstruction Loss: 9926.29296875, KL Divergent: 1278.593505859375\n",
            "Epoch 6/15, Step 260/469, Reconstruction Loss: 10232.076171875, KL Divergent: 1249.81201171875\n",
            "Epoch 6/15, Step 270/469, Reconstruction Loss: 10436.4287109375, KL Divergent: 1254.763671875\n",
            "Epoch 6/15, Step 280/469, Reconstruction Loss: 10542.2109375, KL Divergent: 1346.3736572265625\n",
            "Epoch 6/15, Step 290/469, Reconstruction Loss: 9727.57421875, KL Divergent: 1263.303955078125\n",
            "Epoch 6/15, Step 300/469, Reconstruction Loss: 10456.1953125, KL Divergent: 1214.1458740234375\n",
            "Epoch 6/15, Step 310/469, Reconstruction Loss: 10443.95703125, KL Divergent: 1257.9268798828125\n",
            "Epoch 6/15, Step 320/469, Reconstruction Loss: 9881.5078125, KL Divergent: 1249.143310546875\n",
            "Epoch 6/15, Step 330/469, Reconstruction Loss: 9923.259765625, KL Divergent: 1210.9674072265625\n",
            "Epoch 6/15, Step 340/469, Reconstruction Loss: 10401.076171875, KL Divergent: 1342.82666015625\n",
            "Epoch 6/15, Step 350/469, Reconstruction Loss: 10436.8779296875, KL Divergent: 1299.041748046875\n",
            "Epoch 6/15, Step 360/469, Reconstruction Loss: 10791.609375, KL Divergent: 1307.10498046875\n",
            "Epoch 6/15, Step 370/469, Reconstruction Loss: 10062.1982421875, KL Divergent: 1313.892578125\n",
            "Epoch 6/15, Step 380/469, Reconstruction Loss: 9651.8046875, KL Divergent: 1236.7225341796875\n",
            "Epoch 6/15, Step 390/469, Reconstruction Loss: 10285.5703125, KL Divergent: 1278.662841796875\n",
            "Epoch 6/15, Step 400/469, Reconstruction Loss: 9955.75, KL Divergent: 1254.08642578125\n",
            "Epoch 6/15, Step 410/469, Reconstruction Loss: 10431.25390625, KL Divergent: 1309.533203125\n",
            "Epoch 6/15, Step 420/469, Reconstruction Loss: 10317.3671875, KL Divergent: 1257.5665283203125\n",
            "Epoch 6/15, Step 430/469, Reconstruction Loss: 9907.9228515625, KL Divergent: 1256.5279541015625\n",
            "Epoch 6/15, Step 440/469, Reconstruction Loss: 10158.38671875, KL Divergent: 1277.095947265625\n",
            "Epoch 6/15, Step 450/469, Reconstruction Loss: 10264.603515625, KL Divergent: 1289.65478515625\n",
            "Epoch 6/15, Step 460/469, Reconstruction Loss: 10587.76171875, KL Divergent: 1348.4371337890625\n",
            "Epoch 7/15, Step 10/469, Reconstruction Loss: 10159.5087890625, KL Divergent: 1306.4134521484375\n",
            "Epoch 7/15, Step 20/469, Reconstruction Loss: 9980.70703125, KL Divergent: 1237.912841796875\n",
            "Epoch 7/15, Step 30/469, Reconstruction Loss: 10271.1513671875, KL Divergent: 1316.93994140625\n",
            "Epoch 7/15, Step 40/469, Reconstruction Loss: 10445.25, KL Divergent: 1314.263671875\n",
            "Epoch 7/15, Step 50/469, Reconstruction Loss: 9805.1962890625, KL Divergent: 1235.8563232421875\n",
            "Epoch 7/15, Step 60/469, Reconstruction Loss: 10047.025390625, KL Divergent: 1249.900634765625\n",
            "Epoch 7/15, Step 70/469, Reconstruction Loss: 10064.4296875, KL Divergent: 1324.5416259765625\n",
            "Epoch 7/15, Step 80/469, Reconstruction Loss: 10446.951171875, KL Divergent: 1336.7725830078125\n",
            "Epoch 7/15, Step 90/469, Reconstruction Loss: 10353.8955078125, KL Divergent: 1340.483642578125\n",
            "Epoch 7/15, Step 100/469, Reconstruction Loss: 10107.068359375, KL Divergent: 1239.353515625\n",
            "Epoch 7/15, Step 110/469, Reconstruction Loss: 10334.453125, KL Divergent: 1293.9512939453125\n",
            "Epoch 7/15, Step 120/469, Reconstruction Loss: 10316.828125, KL Divergent: 1281.12841796875\n",
            "Epoch 7/15, Step 130/469, Reconstruction Loss: 9892.2265625, KL Divergent: 1247.134521484375\n",
            "Epoch 7/15, Step 140/469, Reconstruction Loss: 9385.89453125, KL Divergent: 1267.541015625\n",
            "Epoch 7/15, Step 150/469, Reconstruction Loss: 10233.107421875, KL Divergent: 1254.1748046875\n",
            "Epoch 7/15, Step 160/469, Reconstruction Loss: 10350.962890625, KL Divergent: 1284.4715576171875\n",
            "Epoch 7/15, Step 170/469, Reconstruction Loss: 10000.8603515625, KL Divergent: 1234.511962890625\n",
            "Epoch 7/15, Step 180/469, Reconstruction Loss: 10600.1962890625, KL Divergent: 1348.615478515625\n",
            "Epoch 7/15, Step 190/469, Reconstruction Loss: 10519.19140625, KL Divergent: 1272.9688720703125\n",
            "Epoch 7/15, Step 200/469, Reconstruction Loss: 9644.3369140625, KL Divergent: 1251.9620361328125\n",
            "Epoch 7/15, Step 210/469, Reconstruction Loss: 9648.24609375, KL Divergent: 1271.283203125\n",
            "Epoch 7/15, Step 220/469, Reconstruction Loss: 10625.810546875, KL Divergent: 1357.7764892578125\n",
            "Epoch 7/15, Step 230/469, Reconstruction Loss: 10054.58203125, KL Divergent: 1285.725830078125\n",
            "Epoch 7/15, Step 240/469, Reconstruction Loss: 10083.7734375, KL Divergent: 1259.1259765625\n",
            "Epoch 7/15, Step 250/469, Reconstruction Loss: 10318.1064453125, KL Divergent: 1282.44384765625\n",
            "Epoch 7/15, Step 260/469, Reconstruction Loss: 10224.228515625, KL Divergent: 1225.2996826171875\n",
            "Epoch 7/15, Step 270/469, Reconstruction Loss: 9796.232421875, KL Divergent: 1297.09130859375\n",
            "Epoch 7/15, Step 280/469, Reconstruction Loss: 9903.8017578125, KL Divergent: 1273.1173095703125\n",
            "Epoch 7/15, Step 290/469, Reconstruction Loss: 9971.3056640625, KL Divergent: 1349.7667236328125\n",
            "Epoch 7/15, Step 300/469, Reconstruction Loss: 9880.166015625, KL Divergent: 1314.2119140625\n",
            "Epoch 7/15, Step 310/469, Reconstruction Loss: 10505.2109375, KL Divergent: 1262.166259765625\n",
            "Epoch 7/15, Step 320/469, Reconstruction Loss: 10014.544921875, KL Divergent: 1271.6898193359375\n",
            "Epoch 7/15, Step 330/469, Reconstruction Loss: 10393.37890625, KL Divergent: 1325.22265625\n",
            "Epoch 7/15, Step 340/469, Reconstruction Loss: 10097.556640625, KL Divergent: 1325.2222900390625\n",
            "Epoch 7/15, Step 350/469, Reconstruction Loss: 10266.873046875, KL Divergent: 1298.2760009765625\n",
            "Epoch 7/15, Step 360/469, Reconstruction Loss: 10312.4609375, KL Divergent: 1330.041015625\n",
            "Epoch 7/15, Step 370/469, Reconstruction Loss: 10505.33984375, KL Divergent: 1262.1845703125\n",
            "Epoch 7/15, Step 380/469, Reconstruction Loss: 10116.93359375, KL Divergent: 1302.685791015625\n",
            "Epoch 7/15, Step 390/469, Reconstruction Loss: 10344.32421875, KL Divergent: 1206.23779296875\n",
            "Epoch 7/15, Step 400/469, Reconstruction Loss: 9928.44140625, KL Divergent: 1253.5892333984375\n",
            "Epoch 7/15, Step 410/469, Reconstruction Loss: 10035.673828125, KL Divergent: 1299.3984375\n",
            "Epoch 7/15, Step 420/469, Reconstruction Loss: 10191.072265625, KL Divergent: 1228.8184814453125\n",
            "Epoch 7/15, Step 430/469, Reconstruction Loss: 10188.34765625, KL Divergent: 1283.2403564453125\n",
            "Epoch 7/15, Step 440/469, Reconstruction Loss: 10287.7412109375, KL Divergent: 1303.932373046875\n",
            "Epoch 7/15, Step 450/469, Reconstruction Loss: 10338.40234375, KL Divergent: 1293.3841552734375\n",
            "Epoch 7/15, Step 460/469, Reconstruction Loss: 10116.896484375, KL Divergent: 1285.1253662109375\n",
            "Epoch 8/15, Step 10/469, Reconstruction Loss: 10551.1533203125, KL Divergent: 1352.888427734375\n",
            "Epoch 8/15, Step 20/469, Reconstruction Loss: 10232.8701171875, KL Divergent: 1272.27978515625\n",
            "Epoch 8/15, Step 30/469, Reconstruction Loss: 10027.861328125, KL Divergent: 1303.9063720703125\n",
            "Epoch 8/15, Step 40/469, Reconstruction Loss: 9815.4345703125, KL Divergent: 1292.4388427734375\n",
            "Epoch 8/15, Step 50/469, Reconstruction Loss: 10818.833984375, KL Divergent: 1354.2640380859375\n",
            "Epoch 8/15, Step 60/469, Reconstruction Loss: 10010.080078125, KL Divergent: 1249.7757568359375\n",
            "Epoch 8/15, Step 70/469, Reconstruction Loss: 10061.3662109375, KL Divergent: 1274.638427734375\n",
            "Epoch 8/15, Step 80/469, Reconstruction Loss: 10263.64453125, KL Divergent: 1298.261474609375\n",
            "Epoch 8/15, Step 90/469, Reconstruction Loss: 9621.2587890625, KL Divergent: 1248.6993408203125\n",
            "Epoch 8/15, Step 100/469, Reconstruction Loss: 10181.6943359375, KL Divergent: 1300.8721923828125\n",
            "Epoch 8/15, Step 110/469, Reconstruction Loss: 9970.501953125, KL Divergent: 1281.3526611328125\n",
            "Epoch 8/15, Step 120/469, Reconstruction Loss: 10032.173828125, KL Divergent: 1261.9522705078125\n",
            "Epoch 8/15, Step 130/469, Reconstruction Loss: 9867.2265625, KL Divergent: 1284.3370361328125\n",
            "Epoch 8/15, Step 140/469, Reconstruction Loss: 9939.962890625, KL Divergent: 1281.3929443359375\n",
            "Epoch 8/15, Step 150/469, Reconstruction Loss: 10195.99609375, KL Divergent: 1316.515869140625\n",
            "Epoch 8/15, Step 160/469, Reconstruction Loss: 10239.875, KL Divergent: 1301.15966796875\n",
            "Epoch 8/15, Step 170/469, Reconstruction Loss: 9718.666015625, KL Divergent: 1283.680908203125\n",
            "Epoch 8/15, Step 180/469, Reconstruction Loss: 10446.474609375, KL Divergent: 1295.9915771484375\n",
            "Epoch 8/15, Step 190/469, Reconstruction Loss: 9854.19921875, KL Divergent: 1274.07666015625\n",
            "Epoch 8/15, Step 200/469, Reconstruction Loss: 10007.8916015625, KL Divergent: 1281.0003662109375\n",
            "Epoch 8/15, Step 210/469, Reconstruction Loss: 10112.7734375, KL Divergent: 1246.6199951171875\n",
            "Epoch 8/15, Step 220/469, Reconstruction Loss: 10301.294921875, KL Divergent: 1305.6767578125\n",
            "Epoch 8/15, Step 230/469, Reconstruction Loss: 10286.384765625, KL Divergent: 1301.60595703125\n",
            "Epoch 8/15, Step 240/469, Reconstruction Loss: 9929.0185546875, KL Divergent: 1246.849365234375\n",
            "Epoch 8/15, Step 250/469, Reconstruction Loss: 9773.267578125, KL Divergent: 1357.510986328125\n",
            "Epoch 8/15, Step 260/469, Reconstruction Loss: 10022.6552734375, KL Divergent: 1280.0531005859375\n",
            "Epoch 8/15, Step 270/469, Reconstruction Loss: 9830.40234375, KL Divergent: 1295.26123046875\n",
            "Epoch 8/15, Step 280/469, Reconstruction Loss: 10295.3896484375, KL Divergent: 1234.90869140625\n",
            "Epoch 8/15, Step 290/469, Reconstruction Loss: 9915.1455078125, KL Divergent: 1301.1260986328125\n",
            "Epoch 8/15, Step 300/469, Reconstruction Loss: 9536.615234375, KL Divergent: 1269.619873046875\n",
            "Epoch 8/15, Step 310/469, Reconstruction Loss: 9967.7060546875, KL Divergent: 1304.709228515625\n",
            "Epoch 8/15, Step 320/469, Reconstruction Loss: 10107.9013671875, KL Divergent: 1290.9466552734375\n",
            "Epoch 8/15, Step 330/469, Reconstruction Loss: 10000.404296875, KL Divergent: 1289.13818359375\n",
            "Epoch 8/15, Step 340/469, Reconstruction Loss: 9982.59765625, KL Divergent: 1273.328857421875\n",
            "Epoch 8/15, Step 350/469, Reconstruction Loss: 10169.6884765625, KL Divergent: 1319.037841796875\n",
            "Epoch 8/15, Step 360/469, Reconstruction Loss: 10128.306640625, KL Divergent: 1273.154541015625\n",
            "Epoch 8/15, Step 370/469, Reconstruction Loss: 10552.357421875, KL Divergent: 1304.3046875\n",
            "Epoch 8/15, Step 380/469, Reconstruction Loss: 9924.2158203125, KL Divergent: 1332.012451171875\n",
            "Epoch 8/15, Step 390/469, Reconstruction Loss: 10081.6533203125, KL Divergent: 1279.677734375\n",
            "Epoch 8/15, Step 400/469, Reconstruction Loss: 9814.720703125, KL Divergent: 1285.318115234375\n",
            "Epoch 8/15, Step 410/469, Reconstruction Loss: 9789.8623046875, KL Divergent: 1259.744873046875\n",
            "Epoch 8/15, Step 420/469, Reconstruction Loss: 10475.083984375, KL Divergent: 1309.13427734375\n",
            "Epoch 8/15, Step 430/469, Reconstruction Loss: 9959.771484375, KL Divergent: 1292.98681640625\n",
            "Epoch 8/15, Step 440/469, Reconstruction Loss: 9966.3828125, KL Divergent: 1237.708251953125\n",
            "Epoch 8/15, Step 450/469, Reconstruction Loss: 9664.21875, KL Divergent: 1330.7784423828125\n",
            "Epoch 8/15, Step 460/469, Reconstruction Loss: 9640.4296875, KL Divergent: 1263.60009765625\n",
            "Epoch 9/15, Step 10/469, Reconstruction Loss: 10049.658203125, KL Divergent: 1311.3153076171875\n",
            "Epoch 9/15, Step 20/469, Reconstruction Loss: 10270.88671875, KL Divergent: 1277.94140625\n",
            "Epoch 9/15, Step 30/469, Reconstruction Loss: 9557.439453125, KL Divergent: 1255.768310546875\n",
            "Epoch 9/15, Step 40/469, Reconstruction Loss: 10151.251953125, KL Divergent: 1274.32080078125\n",
            "Epoch 9/15, Step 50/469, Reconstruction Loss: 9854.869140625, KL Divergent: 1251.6162109375\n",
            "Epoch 9/15, Step 60/469, Reconstruction Loss: 9650.173828125, KL Divergent: 1242.304443359375\n",
            "Epoch 9/15, Step 70/469, Reconstruction Loss: 9379.3828125, KL Divergent: 1230.465087890625\n",
            "Epoch 9/15, Step 80/469, Reconstruction Loss: 10518.830078125, KL Divergent: 1303.68505859375\n",
            "Epoch 9/15, Step 90/469, Reconstruction Loss: 9815.8125, KL Divergent: 1235.1798095703125\n",
            "Epoch 9/15, Step 100/469, Reconstruction Loss: 9399.7060546875, KL Divergent: 1233.677734375\n",
            "Epoch 9/15, Step 110/469, Reconstruction Loss: 10306.21484375, KL Divergent: 1359.801513671875\n",
            "Epoch 9/15, Step 120/469, Reconstruction Loss: 10236.84765625, KL Divergent: 1338.003173828125\n",
            "Epoch 9/15, Step 130/469, Reconstruction Loss: 9944.416015625, KL Divergent: 1269.49365234375\n",
            "Epoch 9/15, Step 140/469, Reconstruction Loss: 10294.88671875, KL Divergent: 1327.428466796875\n",
            "Epoch 9/15, Step 150/469, Reconstruction Loss: 10101.2998046875, KL Divergent: 1277.3946533203125\n",
            "Epoch 9/15, Step 160/469, Reconstruction Loss: 10118.1279296875, KL Divergent: 1235.5869140625\n",
            "Epoch 9/15, Step 170/469, Reconstruction Loss: 9969.162109375, KL Divergent: 1242.9530029296875\n",
            "Epoch 9/15, Step 180/469, Reconstruction Loss: 9901.755859375, KL Divergent: 1323.241943359375\n",
            "Epoch 9/15, Step 190/469, Reconstruction Loss: 10144.7763671875, KL Divergent: 1297.1209716796875\n",
            "Epoch 9/15, Step 200/469, Reconstruction Loss: 10340.123046875, KL Divergent: 1282.118408203125\n",
            "Epoch 9/15, Step 210/469, Reconstruction Loss: 9897.052734375, KL Divergent: 1290.387451171875\n",
            "Epoch 9/15, Step 220/469, Reconstruction Loss: 9917.150390625, KL Divergent: 1330.9244384765625\n",
            "Epoch 9/15, Step 230/469, Reconstruction Loss: 10009.125, KL Divergent: 1318.9654541015625\n",
            "Epoch 9/15, Step 240/469, Reconstruction Loss: 9646.888671875, KL Divergent: 1302.208984375\n",
            "Epoch 9/15, Step 250/469, Reconstruction Loss: 9476.568359375, KL Divergent: 1234.4794921875\n",
            "Epoch 9/15, Step 260/469, Reconstruction Loss: 10131.1748046875, KL Divergent: 1275.988037109375\n",
            "Epoch 9/15, Step 270/469, Reconstruction Loss: 9945.94921875, KL Divergent: 1288.3265380859375\n",
            "Epoch 9/15, Step 280/469, Reconstruction Loss: 10149.208984375, KL Divergent: 1320.4119873046875\n",
            "Epoch 9/15, Step 290/469, Reconstruction Loss: 9971.533203125, KL Divergent: 1276.5792236328125\n",
            "Epoch 9/15, Step 300/469, Reconstruction Loss: 9978.423828125, KL Divergent: 1244.7601318359375\n",
            "Epoch 9/15, Step 310/469, Reconstruction Loss: 9720.57421875, KL Divergent: 1277.065185546875\n",
            "Epoch 9/15, Step 320/469, Reconstruction Loss: 9833.25, KL Divergent: 1292.069580078125\n",
            "Epoch 9/15, Step 330/469, Reconstruction Loss: 9878.546875, KL Divergent: 1235.152099609375\n",
            "Epoch 9/15, Step 340/469, Reconstruction Loss: 10013.189453125, KL Divergent: 1263.095703125\n",
            "Epoch 9/15, Step 350/469, Reconstruction Loss: 10122.369140625, KL Divergent: 1300.629638671875\n",
            "Epoch 9/15, Step 360/469, Reconstruction Loss: 9894.48046875, KL Divergent: 1302.988037109375\n",
            "Epoch 9/15, Step 370/469, Reconstruction Loss: 10074.18359375, KL Divergent: 1257.50732421875\n",
            "Epoch 9/15, Step 380/469, Reconstruction Loss: 9773.73828125, KL Divergent: 1280.4775390625\n",
            "Epoch 9/15, Step 390/469, Reconstruction Loss: 9847.27734375, KL Divergent: 1312.70947265625\n",
            "Epoch 9/15, Step 400/469, Reconstruction Loss: 10134.11328125, KL Divergent: 1226.3726806640625\n",
            "Epoch 9/15, Step 410/469, Reconstruction Loss: 9808.625, KL Divergent: 1271.291259765625\n",
            "Epoch 9/15, Step 420/469, Reconstruction Loss: 10233.0546875, KL Divergent: 1272.601318359375\n",
            "Epoch 9/15, Step 430/469, Reconstruction Loss: 10504.662109375, KL Divergent: 1348.9180908203125\n",
            "Epoch 9/15, Step 440/469, Reconstruction Loss: 10079.583984375, KL Divergent: 1328.1424560546875\n",
            "Epoch 9/15, Step 450/469, Reconstruction Loss: 10259.783203125, KL Divergent: 1268.083740234375\n",
            "Epoch 9/15, Step 460/469, Reconstruction Loss: 9843.05078125, KL Divergent: 1264.2353515625\n",
            "Epoch 10/15, Step 10/469, Reconstruction Loss: 10005.078125, KL Divergent: 1315.350830078125\n",
            "Epoch 10/15, Step 20/469, Reconstruction Loss: 9982.4091796875, KL Divergent: 1279.365966796875\n",
            "Epoch 10/15, Step 30/469, Reconstruction Loss: 10491.990234375, KL Divergent: 1332.6268310546875\n",
            "Epoch 10/15, Step 40/469, Reconstruction Loss: 10433.404296875, KL Divergent: 1322.747314453125\n",
            "Epoch 10/15, Step 50/469, Reconstruction Loss: 9476.7734375, KL Divergent: 1259.671875\n",
            "Epoch 10/15, Step 60/469, Reconstruction Loss: 9967.857421875, KL Divergent: 1239.302490234375\n",
            "Epoch 10/15, Step 70/469, Reconstruction Loss: 9661.392578125, KL Divergent: 1295.058349609375\n",
            "Epoch 10/15, Step 80/469, Reconstruction Loss: 10271.453125, KL Divergent: 1320.7158203125\n",
            "Epoch 10/15, Step 90/469, Reconstruction Loss: 9596.73046875, KL Divergent: 1236.036376953125\n",
            "Epoch 10/15, Step 100/469, Reconstruction Loss: 9713.37890625, KL Divergent: 1327.0443115234375\n",
            "Epoch 10/15, Step 110/469, Reconstruction Loss: 9340.3720703125, KL Divergent: 1281.162841796875\n",
            "Epoch 10/15, Step 120/469, Reconstruction Loss: 9700.341796875, KL Divergent: 1339.3587646484375\n",
            "Epoch 10/15, Step 130/469, Reconstruction Loss: 9770.53125, KL Divergent: 1221.9541015625\n",
            "Epoch 10/15, Step 140/469, Reconstruction Loss: 9676.017578125, KL Divergent: 1256.0107421875\n",
            "Epoch 10/15, Step 150/469, Reconstruction Loss: 9978.337890625, KL Divergent: 1283.0281982421875\n",
            "Epoch 10/15, Step 160/469, Reconstruction Loss: 10013.287109375, KL Divergent: 1325.0042724609375\n",
            "Epoch 10/15, Step 170/469, Reconstruction Loss: 9842.890625, KL Divergent: 1265.9920654296875\n",
            "Epoch 10/15, Step 180/469, Reconstruction Loss: 9877.2490234375, KL Divergent: 1275.50634765625\n",
            "Epoch 10/15, Step 190/469, Reconstruction Loss: 9924.044921875, KL Divergent: 1284.127197265625\n",
            "Epoch 10/15, Step 200/469, Reconstruction Loss: 9319.154296875, KL Divergent: 1245.319091796875\n",
            "Epoch 10/15, Step 210/469, Reconstruction Loss: 9697.58984375, KL Divergent: 1306.084228515625\n",
            "Epoch 10/15, Step 220/469, Reconstruction Loss: 9952.0302734375, KL Divergent: 1313.643310546875\n",
            "Epoch 10/15, Step 230/469, Reconstruction Loss: 9594.673828125, KL Divergent: 1304.5794677734375\n",
            "Epoch 10/15, Step 240/469, Reconstruction Loss: 9944.0302734375, KL Divergent: 1233.685546875\n",
            "Epoch 10/15, Step 250/469, Reconstruction Loss: 9821.330078125, KL Divergent: 1279.08837890625\n",
            "Epoch 10/15, Step 260/469, Reconstruction Loss: 10049.6298828125, KL Divergent: 1286.8402099609375\n",
            "Epoch 10/15, Step 270/469, Reconstruction Loss: 10242.33984375, KL Divergent: 1312.2490234375\n",
            "Epoch 10/15, Step 280/469, Reconstruction Loss: 10120.552734375, KL Divergent: 1363.57177734375\n",
            "Epoch 10/15, Step 290/469, Reconstruction Loss: 10199.5224609375, KL Divergent: 1299.6019287109375\n",
            "Epoch 10/15, Step 300/469, Reconstruction Loss: 9393.23046875, KL Divergent: 1272.81787109375\n",
            "Epoch 10/15, Step 310/469, Reconstruction Loss: 9934.28515625, KL Divergent: 1259.9688720703125\n",
            "Epoch 10/15, Step 320/469, Reconstruction Loss: 9865.78515625, KL Divergent: 1284.0919189453125\n",
            "Epoch 10/15, Step 330/469, Reconstruction Loss: 10114.23046875, KL Divergent: 1289.27197265625\n",
            "Epoch 10/15, Step 340/469, Reconstruction Loss: 9955.345703125, KL Divergent: 1291.7572021484375\n",
            "Epoch 10/15, Step 350/469, Reconstruction Loss: 9808.771484375, KL Divergent: 1270.984130859375\n",
            "Epoch 10/15, Step 360/469, Reconstruction Loss: 9228.48828125, KL Divergent: 1253.542724609375\n",
            "Epoch 10/15, Step 370/469, Reconstruction Loss: 9818.951171875, KL Divergent: 1285.3212890625\n",
            "Epoch 10/15, Step 380/469, Reconstruction Loss: 9884.580078125, KL Divergent: 1263.028076171875\n",
            "Epoch 10/15, Step 390/469, Reconstruction Loss: 9595.25390625, KL Divergent: 1296.470703125\n",
            "Epoch 10/15, Step 400/469, Reconstruction Loss: 9458.4775390625, KL Divergent: 1271.208740234375\n",
            "Epoch 10/15, Step 410/469, Reconstruction Loss: 9156.734375, KL Divergent: 1248.184814453125\n",
            "Epoch 10/15, Step 420/469, Reconstruction Loss: 9997.56640625, KL Divergent: 1352.1097412109375\n",
            "Epoch 10/15, Step 430/469, Reconstruction Loss: 9938.314453125, KL Divergent: 1292.511962890625\n",
            "Epoch 10/15, Step 440/469, Reconstruction Loss: 9630.39453125, KL Divergent: 1233.567138671875\n",
            "Epoch 10/15, Step 450/469, Reconstruction Loss: 10110.279296875, KL Divergent: 1334.55322265625\n",
            "Epoch 10/15, Step 460/469, Reconstruction Loss: 9562.5107421875, KL Divergent: 1230.125\n",
            "Epoch 11/15, Step 10/469, Reconstruction Loss: 10393.8154296875, KL Divergent: 1322.0623779296875\n",
            "Epoch 11/15, Step 20/469, Reconstruction Loss: 10079.7373046875, KL Divergent: 1306.234619140625\n",
            "Epoch 11/15, Step 30/469, Reconstruction Loss: 9726.5048828125, KL Divergent: 1234.943115234375\n",
            "Epoch 11/15, Step 40/469, Reconstruction Loss: 9810.396484375, KL Divergent: 1267.79296875\n",
            "Epoch 11/15, Step 50/469, Reconstruction Loss: 9707.0966796875, KL Divergent: 1282.922607421875\n",
            "Epoch 11/15, Step 60/469, Reconstruction Loss: 9543.6982421875, KL Divergent: 1230.8525390625\n",
            "Epoch 11/15, Step 70/469, Reconstruction Loss: 9843.9306640625, KL Divergent: 1297.54150390625\n",
            "Epoch 11/15, Step 80/469, Reconstruction Loss: 10368.61328125, KL Divergent: 1339.41748046875\n",
            "Epoch 11/15, Step 90/469, Reconstruction Loss: 9779.7939453125, KL Divergent: 1260.5504150390625\n",
            "Epoch 11/15, Step 100/469, Reconstruction Loss: 9667.6640625, KL Divergent: 1263.664306640625\n",
            "Epoch 11/15, Step 110/469, Reconstruction Loss: 9777.78515625, KL Divergent: 1278.00830078125\n",
            "Epoch 11/15, Step 120/469, Reconstruction Loss: 9996.7626953125, KL Divergent: 1272.8408203125\n",
            "Epoch 11/15, Step 130/469, Reconstruction Loss: 10352.5498046875, KL Divergent: 1297.6883544921875\n",
            "Epoch 11/15, Step 140/469, Reconstruction Loss: 10161.962890625, KL Divergent: 1296.7188720703125\n",
            "Epoch 11/15, Step 150/469, Reconstruction Loss: 10023.78515625, KL Divergent: 1314.538330078125\n",
            "Epoch 11/15, Step 160/469, Reconstruction Loss: 9872.068359375, KL Divergent: 1269.531005859375\n",
            "Epoch 11/15, Step 170/469, Reconstruction Loss: 9811.43359375, KL Divergent: 1259.98876953125\n",
            "Epoch 11/15, Step 180/469, Reconstruction Loss: 9592.86328125, KL Divergent: 1233.859619140625\n",
            "Epoch 11/15, Step 190/469, Reconstruction Loss: 9816.37890625, KL Divergent: 1297.74658203125\n",
            "Epoch 11/15, Step 200/469, Reconstruction Loss: 9556.189453125, KL Divergent: 1226.540283203125\n",
            "Epoch 11/15, Step 210/469, Reconstruction Loss: 9744.5439453125, KL Divergent: 1226.71044921875\n",
            "Epoch 11/15, Step 220/469, Reconstruction Loss: 9980.91796875, KL Divergent: 1327.10205078125\n",
            "Epoch 11/15, Step 230/469, Reconstruction Loss: 10059.0234375, KL Divergent: 1274.978271484375\n",
            "Epoch 11/15, Step 240/469, Reconstruction Loss: 9873.419921875, KL Divergent: 1327.2012939453125\n",
            "Epoch 11/15, Step 250/469, Reconstruction Loss: 10463.84375, KL Divergent: 1327.471435546875\n",
            "Epoch 11/15, Step 260/469, Reconstruction Loss: 10106.6875, KL Divergent: 1354.03173828125\n",
            "Epoch 11/15, Step 270/469, Reconstruction Loss: 9708.685546875, KL Divergent: 1272.1754150390625\n",
            "Epoch 11/15, Step 280/469, Reconstruction Loss: 10335.576171875, KL Divergent: 1259.082763671875\n",
            "Epoch 11/15, Step 290/469, Reconstruction Loss: 9404.2880859375, KL Divergent: 1246.56591796875\n",
            "Epoch 11/15, Step 300/469, Reconstruction Loss: 9473.87109375, KL Divergent: 1300.145263671875\n",
            "Epoch 11/15, Step 310/469, Reconstruction Loss: 9602.80078125, KL Divergent: 1264.711181640625\n",
            "Epoch 11/15, Step 320/469, Reconstruction Loss: 9879.033203125, KL Divergent: 1280.0811767578125\n",
            "Epoch 11/15, Step 330/469, Reconstruction Loss: 10021.099609375, KL Divergent: 1283.92578125\n",
            "Epoch 11/15, Step 340/469, Reconstruction Loss: 9207.6162109375, KL Divergent: 1253.2574462890625\n",
            "Epoch 11/15, Step 350/469, Reconstruction Loss: 10027.435546875, KL Divergent: 1326.5458984375\n",
            "Epoch 11/15, Step 360/469, Reconstruction Loss: 9996.6015625, KL Divergent: 1291.11083984375\n",
            "Epoch 11/15, Step 370/469, Reconstruction Loss: 9962.189453125, KL Divergent: 1313.91552734375\n",
            "Epoch 11/15, Step 380/469, Reconstruction Loss: 9552.5, KL Divergent: 1267.4677734375\n",
            "Epoch 11/15, Step 390/469, Reconstruction Loss: 9916.9736328125, KL Divergent: 1264.433837890625\n",
            "Epoch 11/15, Step 400/469, Reconstruction Loss: 9590.283203125, KL Divergent: 1298.779052734375\n",
            "Epoch 11/15, Step 410/469, Reconstruction Loss: 9818.08984375, KL Divergent: 1348.1595458984375\n",
            "Epoch 11/15, Step 420/469, Reconstruction Loss: 9343.150390625, KL Divergent: 1286.35693359375\n",
            "Epoch 11/15, Step 430/469, Reconstruction Loss: 9684.03515625, KL Divergent: 1229.2252197265625\n",
            "Epoch 11/15, Step 440/469, Reconstruction Loss: 9613.650390625, KL Divergent: 1240.8486328125\n",
            "Epoch 11/15, Step 450/469, Reconstruction Loss: 9602.2744140625, KL Divergent: 1268.3013916015625\n",
            "Epoch 11/15, Step 460/469, Reconstruction Loss: 9440.84765625, KL Divergent: 1261.16845703125\n",
            "Epoch 12/15, Step 10/469, Reconstruction Loss: 9917.3984375, KL Divergent: 1277.7666015625\n",
            "Epoch 12/15, Step 20/469, Reconstruction Loss: 9776.1123046875, KL Divergent: 1301.4241943359375\n",
            "Epoch 12/15, Step 30/469, Reconstruction Loss: 10065.814453125, KL Divergent: 1314.8663330078125\n",
            "Epoch 12/15, Step 40/469, Reconstruction Loss: 10096.4140625, KL Divergent: 1348.863037109375\n",
            "Epoch 12/15, Step 50/469, Reconstruction Loss: 9208.8955078125, KL Divergent: 1238.01806640625\n",
            "Epoch 12/15, Step 60/469, Reconstruction Loss: 10078.78515625, KL Divergent: 1308.5869140625\n",
            "Epoch 12/15, Step 70/469, Reconstruction Loss: 9576.8349609375, KL Divergent: 1278.4820556640625\n",
            "Epoch 12/15, Step 80/469, Reconstruction Loss: 10043.587890625, KL Divergent: 1265.4149169921875\n",
            "Epoch 12/15, Step 90/469, Reconstruction Loss: 9762.77734375, KL Divergent: 1293.245361328125\n",
            "Epoch 12/15, Step 100/469, Reconstruction Loss: 9737.759765625, KL Divergent: 1253.3250732421875\n",
            "Epoch 12/15, Step 110/469, Reconstruction Loss: 9923.6796875, KL Divergent: 1312.376953125\n",
            "Epoch 12/15, Step 120/469, Reconstruction Loss: 9431.146484375, KL Divergent: 1297.7723388671875\n",
            "Epoch 12/15, Step 130/469, Reconstruction Loss: 10347.2294921875, KL Divergent: 1355.5908203125\n",
            "Epoch 12/15, Step 140/469, Reconstruction Loss: 9526.2236328125, KL Divergent: 1246.3079833984375\n",
            "Epoch 12/15, Step 150/469, Reconstruction Loss: 9705.7333984375, KL Divergent: 1267.262939453125\n",
            "Epoch 12/15, Step 160/469, Reconstruction Loss: 10083.7412109375, KL Divergent: 1341.4239501953125\n",
            "Epoch 12/15, Step 170/469, Reconstruction Loss: 10011.88671875, KL Divergent: 1279.8370361328125\n",
            "Epoch 12/15, Step 180/469, Reconstruction Loss: 9356.1845703125, KL Divergent: 1286.69091796875\n",
            "Epoch 12/15, Step 190/469, Reconstruction Loss: 9538.837890625, KL Divergent: 1297.05029296875\n",
            "Epoch 12/15, Step 200/469, Reconstruction Loss: 9993.3408203125, KL Divergent: 1290.9814453125\n",
            "Epoch 12/15, Step 210/469, Reconstruction Loss: 9978.060546875, KL Divergent: 1281.327392578125\n",
            "Epoch 12/15, Step 220/469, Reconstruction Loss: 9740.3447265625, KL Divergent: 1268.9476318359375\n",
            "Epoch 12/15, Step 230/469, Reconstruction Loss: 9846.669921875, KL Divergent: 1260.0537109375\n",
            "Epoch 12/15, Step 240/469, Reconstruction Loss: 9688.640625, KL Divergent: 1326.5191650390625\n",
            "Epoch 12/15, Step 250/469, Reconstruction Loss: 9431.64453125, KL Divergent: 1217.5736083984375\n",
            "Epoch 12/15, Step 260/469, Reconstruction Loss: 9972.0703125, KL Divergent: 1269.376220703125\n",
            "Epoch 12/15, Step 270/469, Reconstruction Loss: 10083.63671875, KL Divergent: 1298.6202392578125\n",
            "Epoch 12/15, Step 280/469, Reconstruction Loss: 10150.6376953125, KL Divergent: 1331.92236328125\n",
            "Epoch 12/15, Step 290/469, Reconstruction Loss: 9744.4345703125, KL Divergent: 1293.929931640625\n",
            "Epoch 12/15, Step 300/469, Reconstruction Loss: 9770.001953125, KL Divergent: 1268.9478759765625\n",
            "Epoch 12/15, Step 310/469, Reconstruction Loss: 9502.3662109375, KL Divergent: 1245.204833984375\n",
            "Epoch 12/15, Step 320/469, Reconstruction Loss: 9561.970703125, KL Divergent: 1291.174560546875\n",
            "Epoch 12/15, Step 330/469, Reconstruction Loss: 9304.845703125, KL Divergent: 1257.9033203125\n",
            "Epoch 12/15, Step 340/469, Reconstruction Loss: 9840.091796875, KL Divergent: 1233.18798828125\n",
            "Epoch 12/15, Step 350/469, Reconstruction Loss: 9990.99609375, KL Divergent: 1332.463623046875\n",
            "Epoch 12/15, Step 360/469, Reconstruction Loss: 9753.5537109375, KL Divergent: 1301.8851318359375\n",
            "Epoch 12/15, Step 370/469, Reconstruction Loss: 9999.2109375, KL Divergent: 1333.9854736328125\n",
            "Epoch 12/15, Step 380/469, Reconstruction Loss: 9664.908203125, KL Divergent: 1266.8997802734375\n",
            "Epoch 12/15, Step 390/469, Reconstruction Loss: 10121.01171875, KL Divergent: 1268.06103515625\n",
            "Epoch 12/15, Step 400/469, Reconstruction Loss: 9676.62890625, KL Divergent: 1289.5477294921875\n",
            "Epoch 12/15, Step 410/469, Reconstruction Loss: 10032.45703125, KL Divergent: 1326.51318359375\n",
            "Epoch 12/15, Step 420/469, Reconstruction Loss: 9816.904296875, KL Divergent: 1312.9083251953125\n",
            "Epoch 12/15, Step 430/469, Reconstruction Loss: 9474.7626953125, KL Divergent: 1267.65625\n",
            "Epoch 12/15, Step 440/469, Reconstruction Loss: 9502.6669921875, KL Divergent: 1280.3165283203125\n",
            "Epoch 12/15, Step 450/469, Reconstruction Loss: 9703.4609375, KL Divergent: 1279.48291015625\n",
            "Epoch 12/15, Step 460/469, Reconstruction Loss: 9870.7890625, KL Divergent: 1260.704345703125\n",
            "Epoch 13/15, Step 10/469, Reconstruction Loss: 9901.44140625, KL Divergent: 1303.60107421875\n",
            "Epoch 13/15, Step 20/469, Reconstruction Loss: 9798.375, KL Divergent: 1246.325927734375\n",
            "Epoch 13/15, Step 30/469, Reconstruction Loss: 9905.390625, KL Divergent: 1372.390625\n",
            "Epoch 13/15, Step 40/469, Reconstruction Loss: 9864.291015625, KL Divergent: 1309.91748046875\n",
            "Epoch 13/15, Step 50/469, Reconstruction Loss: 10125.7333984375, KL Divergent: 1319.1639404296875\n",
            "Epoch 13/15, Step 60/469, Reconstruction Loss: 9664.80859375, KL Divergent: 1320.257080078125\n",
            "Epoch 13/15, Step 70/469, Reconstruction Loss: 9279.169921875, KL Divergent: 1235.517333984375\n",
            "Epoch 13/15, Step 80/469, Reconstruction Loss: 9231.8046875, KL Divergent: 1265.934326171875\n",
            "Epoch 13/15, Step 90/469, Reconstruction Loss: 10311.576171875, KL Divergent: 1322.2734375\n",
            "Epoch 13/15, Step 100/469, Reconstruction Loss: 10320.451171875, KL Divergent: 1331.470703125\n",
            "Epoch 13/15, Step 110/469, Reconstruction Loss: 9341.638671875, KL Divergent: 1227.314208984375\n",
            "Epoch 13/15, Step 120/469, Reconstruction Loss: 9641.51953125, KL Divergent: 1266.63330078125\n",
            "Epoch 13/15, Step 130/469, Reconstruction Loss: 9409.279296875, KL Divergent: 1206.333251953125\n",
            "Epoch 13/15, Step 140/469, Reconstruction Loss: 9957.8828125, KL Divergent: 1291.849365234375\n",
            "Epoch 13/15, Step 150/469, Reconstruction Loss: 9634.060546875, KL Divergent: 1270.62890625\n",
            "Epoch 13/15, Step 160/469, Reconstruction Loss: 9758.7568359375, KL Divergent: 1279.87646484375\n",
            "Epoch 13/15, Step 170/469, Reconstruction Loss: 9882.568359375, KL Divergent: 1309.716552734375\n",
            "Epoch 13/15, Step 180/469, Reconstruction Loss: 9542.638671875, KL Divergent: 1278.6768798828125\n",
            "Epoch 13/15, Step 190/469, Reconstruction Loss: 9518.1279296875, KL Divergent: 1269.789306640625\n",
            "Epoch 13/15, Step 200/469, Reconstruction Loss: 9795.9072265625, KL Divergent: 1333.0865478515625\n",
            "Epoch 13/15, Step 210/469, Reconstruction Loss: 9454.94921875, KL Divergent: 1295.696044921875\n",
            "Epoch 13/15, Step 220/469, Reconstruction Loss: 9968.955078125, KL Divergent: 1312.3287353515625\n",
            "Epoch 13/15, Step 230/469, Reconstruction Loss: 9574.4521484375, KL Divergent: 1294.9293212890625\n",
            "Epoch 13/15, Step 240/469, Reconstruction Loss: 9432.5361328125, KL Divergent: 1243.611328125\n",
            "Epoch 13/15, Step 250/469, Reconstruction Loss: 10131.2294921875, KL Divergent: 1295.802490234375\n",
            "Epoch 13/15, Step 260/469, Reconstruction Loss: 9488.337890625, KL Divergent: 1315.706298828125\n",
            "Epoch 13/15, Step 270/469, Reconstruction Loss: 9709.0146484375, KL Divergent: 1301.25390625\n",
            "Epoch 13/15, Step 280/469, Reconstruction Loss: 9564.318359375, KL Divergent: 1294.0322265625\n",
            "Epoch 13/15, Step 290/469, Reconstruction Loss: 9893.6728515625, KL Divergent: 1334.7763671875\n",
            "Epoch 13/15, Step 300/469, Reconstruction Loss: 10188.3681640625, KL Divergent: 1308.184326171875\n",
            "Epoch 13/15, Step 310/469, Reconstruction Loss: 9772.3896484375, KL Divergent: 1311.027587890625\n",
            "Epoch 13/15, Step 320/469, Reconstruction Loss: 9449.8037109375, KL Divergent: 1273.23193359375\n",
            "Epoch 13/15, Step 330/469, Reconstruction Loss: 9491.7353515625, KL Divergent: 1236.566650390625\n",
            "Epoch 13/15, Step 340/469, Reconstruction Loss: 10163.806640625, KL Divergent: 1258.294921875\n",
            "Epoch 13/15, Step 350/469, Reconstruction Loss: 9435.001953125, KL Divergent: 1279.8975830078125\n",
            "Epoch 13/15, Step 360/469, Reconstruction Loss: 9866.908203125, KL Divergent: 1294.238037109375\n",
            "Epoch 13/15, Step 370/469, Reconstruction Loss: 9652.3662109375, KL Divergent: 1249.48486328125\n",
            "Epoch 13/15, Step 380/469, Reconstruction Loss: 9837.3046875, KL Divergent: 1287.559326171875\n",
            "Epoch 13/15, Step 390/469, Reconstruction Loss: 9081.619140625, KL Divergent: 1225.381591796875\n",
            "Epoch 13/15, Step 400/469, Reconstruction Loss: 9670.111328125, KL Divergent: 1296.3173828125\n",
            "Epoch 13/15, Step 410/469, Reconstruction Loss: 9421.455078125, KL Divergent: 1269.1546630859375\n",
            "Epoch 13/15, Step 420/469, Reconstruction Loss: 9968.56640625, KL Divergent: 1279.44677734375\n",
            "Epoch 13/15, Step 430/469, Reconstruction Loss: 9522.828125, KL Divergent: 1268.93701171875\n",
            "Epoch 13/15, Step 440/469, Reconstruction Loss: 9731.1171875, KL Divergent: 1284.759765625\n",
            "Epoch 13/15, Step 450/469, Reconstruction Loss: 9975.38671875, KL Divergent: 1319.097900390625\n",
            "Epoch 13/15, Step 460/469, Reconstruction Loss: 9891.990234375, KL Divergent: 1280.512451171875\n",
            "Epoch 14/15, Step 10/469, Reconstruction Loss: 9594.20703125, KL Divergent: 1227.493896484375\n",
            "Epoch 14/15, Step 20/469, Reconstruction Loss: 9489.83984375, KL Divergent: 1282.99462890625\n",
            "Epoch 14/15, Step 30/469, Reconstruction Loss: 9756.1259765625, KL Divergent: 1304.466796875\n",
            "Epoch 14/15, Step 40/469, Reconstruction Loss: 9801.6123046875, KL Divergent: 1280.896728515625\n",
            "Epoch 14/15, Step 50/469, Reconstruction Loss: 9990.2705078125, KL Divergent: 1312.896728515625\n",
            "Epoch 14/15, Step 60/469, Reconstruction Loss: 9826.81640625, KL Divergent: 1323.17529296875\n",
            "Epoch 14/15, Step 70/469, Reconstruction Loss: 9565.39453125, KL Divergent: 1282.52734375\n",
            "Epoch 14/15, Step 80/469, Reconstruction Loss: 9331.080078125, KL Divergent: 1290.777099609375\n",
            "Epoch 14/15, Step 90/469, Reconstruction Loss: 9311.060546875, KL Divergent: 1296.96484375\n",
            "Epoch 14/15, Step 100/469, Reconstruction Loss: 9784.4296875, KL Divergent: 1318.1842041015625\n",
            "Epoch 14/15, Step 110/469, Reconstruction Loss: 9883.2958984375, KL Divergent: 1302.744140625\n",
            "Epoch 14/15, Step 120/469, Reconstruction Loss: 9526.130859375, KL Divergent: 1312.048828125\n",
            "Epoch 14/15, Step 130/469, Reconstruction Loss: 9917.81640625, KL Divergent: 1277.9638671875\n",
            "Epoch 14/15, Step 140/469, Reconstruction Loss: 9620.7236328125, KL Divergent: 1300.5484619140625\n",
            "Epoch 14/15, Step 150/469, Reconstruction Loss: 9979.375, KL Divergent: 1284.00146484375\n",
            "Epoch 14/15, Step 160/469, Reconstruction Loss: 9586.8994140625, KL Divergent: 1277.6982421875\n",
            "Epoch 14/15, Step 170/469, Reconstruction Loss: 10057.271484375, KL Divergent: 1342.61865234375\n",
            "Epoch 14/15, Step 180/469, Reconstruction Loss: 10082.28515625, KL Divergent: 1294.9375\n",
            "Epoch 14/15, Step 190/469, Reconstruction Loss: 10213.19921875, KL Divergent: 1329.516357421875\n",
            "Epoch 14/15, Step 200/469, Reconstruction Loss: 9499.953125, KL Divergent: 1275.79248046875\n",
            "Epoch 14/15, Step 210/469, Reconstruction Loss: 9213.9716796875, KL Divergent: 1299.44775390625\n",
            "Epoch 14/15, Step 220/469, Reconstruction Loss: 9903.611328125, KL Divergent: 1261.9521484375\n",
            "Epoch 14/15, Step 230/469, Reconstruction Loss: 9737.26171875, KL Divergent: 1274.17724609375\n",
            "Epoch 14/15, Step 240/469, Reconstruction Loss: 9811.8837890625, KL Divergent: 1290.41455078125\n",
            "Epoch 14/15, Step 250/469, Reconstruction Loss: 9899.677734375, KL Divergent: 1269.91259765625\n",
            "Epoch 14/15, Step 260/469, Reconstruction Loss: 9454.1640625, KL Divergent: 1289.1328125\n",
            "Epoch 14/15, Step 270/469, Reconstruction Loss: 9666.1015625, KL Divergent: 1321.729736328125\n",
            "Epoch 14/15, Step 280/469, Reconstruction Loss: 9433.865234375, KL Divergent: 1291.380126953125\n",
            "Epoch 14/15, Step 290/469, Reconstruction Loss: 9786.45703125, KL Divergent: 1351.296875\n",
            "Epoch 14/15, Step 300/469, Reconstruction Loss: 9116.515625, KL Divergent: 1262.754150390625\n",
            "Epoch 14/15, Step 310/469, Reconstruction Loss: 10081.44921875, KL Divergent: 1297.84912109375\n",
            "Epoch 14/15, Step 320/469, Reconstruction Loss: 9930.41796875, KL Divergent: 1260.263671875\n",
            "Epoch 14/15, Step 330/469, Reconstruction Loss: 9352.298828125, KL Divergent: 1317.99609375\n",
            "Epoch 14/15, Step 340/469, Reconstruction Loss: 9879.724609375, KL Divergent: 1320.72998046875\n",
            "Epoch 14/15, Step 350/469, Reconstruction Loss: 9565.990234375, KL Divergent: 1249.897705078125\n",
            "Epoch 14/15, Step 360/469, Reconstruction Loss: 9841.84765625, KL Divergent: 1259.3575439453125\n",
            "Epoch 14/15, Step 370/469, Reconstruction Loss: 9822.494140625, KL Divergent: 1324.514404296875\n",
            "Epoch 14/15, Step 380/469, Reconstruction Loss: 9691.982421875, KL Divergent: 1313.11279296875\n",
            "Epoch 14/15, Step 390/469, Reconstruction Loss: 9843.6240234375, KL Divergent: 1286.875732421875\n",
            "Epoch 14/15, Step 400/469, Reconstruction Loss: 9515.5859375, KL Divergent: 1297.311279296875\n",
            "Epoch 14/15, Step 410/469, Reconstruction Loss: 9842.7109375, KL Divergent: 1245.75439453125\n",
            "Epoch 14/15, Step 420/469, Reconstruction Loss: 9477.3740234375, KL Divergent: 1227.87939453125\n",
            "Epoch 14/15, Step 430/469, Reconstruction Loss: 9500.890625, KL Divergent: 1266.014404296875\n",
            "Epoch 14/15, Step 440/469, Reconstruction Loss: 9599.107421875, KL Divergent: 1287.542236328125\n",
            "Epoch 14/15, Step 450/469, Reconstruction Loss: 9595.3984375, KL Divergent: 1282.107177734375\n",
            "Epoch 14/15, Step 460/469, Reconstruction Loss: 9756.822265625, KL Divergent: 1287.45556640625\n",
            "Epoch 15/15, Step 10/469, Reconstruction Loss: 9663.3671875, KL Divergent: 1337.896728515625\n",
            "Epoch 15/15, Step 20/469, Reconstruction Loss: 9865.123046875, KL Divergent: 1292.8779296875\n",
            "Epoch 15/15, Step 30/469, Reconstruction Loss: 9733.447265625, KL Divergent: 1290.2705078125\n",
            "Epoch 15/15, Step 40/469, Reconstruction Loss: 9901.818359375, KL Divergent: 1305.56689453125\n",
            "Epoch 15/15, Step 50/469, Reconstruction Loss: 9217.158203125, KL Divergent: 1230.3211669921875\n",
            "Epoch 15/15, Step 60/469, Reconstruction Loss: 9588.908203125, KL Divergent: 1319.67529296875\n",
            "Epoch 15/15, Step 70/469, Reconstruction Loss: 9769.8330078125, KL Divergent: 1311.212646484375\n",
            "Epoch 15/15, Step 80/469, Reconstruction Loss: 9917.5712890625, KL Divergent: 1276.507568359375\n",
            "Epoch 15/15, Step 90/469, Reconstruction Loss: 9667.0703125, KL Divergent: 1331.6220703125\n",
            "Epoch 15/15, Step 100/469, Reconstruction Loss: 9505.5849609375, KL Divergent: 1269.888916015625\n",
            "Epoch 15/15, Step 110/469, Reconstruction Loss: 9495.29296875, KL Divergent: 1229.80029296875\n",
            "Epoch 15/15, Step 120/469, Reconstruction Loss: 9802.84375, KL Divergent: 1331.181884765625\n",
            "Epoch 15/15, Step 130/469, Reconstruction Loss: 9904.0625, KL Divergent: 1303.377197265625\n",
            "Epoch 15/15, Step 140/469, Reconstruction Loss: 9709.80078125, KL Divergent: 1271.3253173828125\n",
            "Epoch 15/15, Step 150/469, Reconstruction Loss: 9687.134765625, KL Divergent: 1305.662841796875\n",
            "Epoch 15/15, Step 160/469, Reconstruction Loss: 9504.61328125, KL Divergent: 1251.691650390625\n",
            "Epoch 15/15, Step 170/469, Reconstruction Loss: 9846.2607421875, KL Divergent: 1290.898193359375\n",
            "Epoch 15/15, Step 180/469, Reconstruction Loss: 10235.4638671875, KL Divergent: 1342.8446044921875\n",
            "Epoch 15/15, Step 190/469, Reconstruction Loss: 9686.853515625, KL Divergent: 1283.6044921875\n",
            "Epoch 15/15, Step 200/469, Reconstruction Loss: 9697.154296875, KL Divergent: 1317.0087890625\n",
            "Epoch 15/15, Step 210/469, Reconstruction Loss: 9255.15234375, KL Divergent: 1259.9058837890625\n",
            "Epoch 15/15, Step 220/469, Reconstruction Loss: 10270.9453125, KL Divergent: 1317.09521484375\n",
            "Epoch 15/15, Step 230/469, Reconstruction Loss: 9445.041015625, KL Divergent: 1328.5897216796875\n",
            "Epoch 15/15, Step 240/469, Reconstruction Loss: 9482.87890625, KL Divergent: 1271.0797119140625\n",
            "Epoch 15/15, Step 250/469, Reconstruction Loss: 9617.505859375, KL Divergent: 1257.4957275390625\n",
            "Epoch 15/15, Step 260/469, Reconstruction Loss: 9287.22265625, KL Divergent: 1272.04443359375\n",
            "Epoch 15/15, Step 270/469, Reconstruction Loss: 9518.85546875, KL Divergent: 1279.19189453125\n",
            "Epoch 15/15, Step 280/469, Reconstruction Loss: 10037.90625, KL Divergent: 1323.92822265625\n",
            "Epoch 15/15, Step 290/469, Reconstruction Loss: 9433.099609375, KL Divergent: 1261.7535400390625\n",
            "Epoch 15/15, Step 300/469, Reconstruction Loss: 9622.7763671875, KL Divergent: 1291.964111328125\n",
            "Epoch 15/15, Step 310/469, Reconstruction Loss: 9684.3095703125, KL Divergent: 1293.05419921875\n",
            "Epoch 15/15, Step 320/469, Reconstruction Loss: 9350.7578125, KL Divergent: 1281.4266357421875\n",
            "Epoch 15/15, Step 330/469, Reconstruction Loss: 9702.41015625, KL Divergent: 1249.0487060546875\n",
            "Epoch 15/15, Step 340/469, Reconstruction Loss: 9861.783203125, KL Divergent: 1308.5333251953125\n",
            "Epoch 15/15, Step 350/469, Reconstruction Loss: 9914.16015625, KL Divergent: 1290.810546875\n",
            "Epoch 15/15, Step 360/469, Reconstruction Loss: 9858.21484375, KL Divergent: 1261.7806396484375\n",
            "Epoch 15/15, Step 370/469, Reconstruction Loss: 9382.220703125, KL Divergent: 1284.798583984375\n",
            "Epoch 15/15, Step 380/469, Reconstruction Loss: 9639.8515625, KL Divergent: 1275.5072021484375\n",
            "Epoch 15/15, Step 390/469, Reconstruction Loss: 9439.6865234375, KL Divergent: 1287.858642578125\n",
            "Epoch 15/15, Step 400/469, Reconstruction Loss: 9565.99609375, KL Divergent: 1269.2779541015625\n",
            "Epoch 15/15, Step 410/469, Reconstruction Loss: 9645.666015625, KL Divergent: 1284.85595703125\n",
            "Epoch 15/15, Step 420/469, Reconstruction Loss: 9742.169921875, KL Divergent: 1289.53662109375\n",
            "Epoch 15/15, Step 430/469, Reconstruction Loss: 9681.87109375, KL Divergent: 1233.0478515625\n",
            "Epoch 15/15, Step 440/469, Reconstruction Loss: 9714.6484375, KL Divergent: 1355.35205078125\n",
            "Epoch 15/15, Step 450/469, Reconstruction Loss: 9859.888671875, KL Divergent: 1300.895751953125\n",
            "Epoch 15/15, Step 460/469, Reconstruction Loss: 10145.41796875, KL Divergent: 1340.782958984375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate images using the trained model\n",
        "with torch.no_grad():\n",
        "\n",
        "  # Save the sampled images\n",
        "  z = torch.randn(batch_size, z_dim).to(device)\n",
        "  outputs = model.decode(z).view(-1, 1, 28, 28)\n",
        "  save_image(outputs, os.path.join(dir, 'sampled-{}.png'.format(i+1)))\n",
        "\n",
        "  # Save the reconstructed images\n",
        "  out, _, _ = model(images)\n",
        "  x_concat = torch.cat([images.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
        "  save_image(x_concat, os.path.join(dir, 'reconst-{}.png'.format(e+1)))"
      ],
      "metadata": {
        "id": "4TxF9QspVp-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}